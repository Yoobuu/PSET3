{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0594eb",
   "metadata": {},
   "source": [
    "variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fe11af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------+--------+---+\n",
      "|ACCOUNT |REGION       |ROLE    |DB      |SCH|\n",
      "+--------+-------------+--------+--------+---+\n",
      "|XPC24435|AWS_US_EAST_1|SYSADMIN|DM_PSET3|RAW|\n",
      "+--------+-------------+--------+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# iniciar SparkSession\n",
    "spark = SparkSession.builder.appName(\"SnowflakeConnectionTest\").getOrCreate()\n",
    "\n",
    "# opciones Snowflake desde .env\n",
    "sfOptions = {\n",
    "    \"sfURL\": os.getenv(\"SNOWFLAKE_HOST\"),      # sin :443\n",
    "    \"sfPort\": os.getenv(\"SNOWFLAKE_PORT\", \"443\"),\n",
    "    \"sfDatabase\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"sfSchema\": os.getenv(\"SNOWFLAKE_SCHEMA_RAW\"),\n",
    "    \"sfWarehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"sfRole\": os.getenv(\"SNOWFLAKE_ROLE\"),\n",
    "    \"sfUser\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"sfPassword\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "}\n",
    "\n",
    "# consulta de prueba (solo lectura)\n",
    "probe = (\n",
    "    spark.read\n",
    "    .format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\n",
    "        \"query\",\n",
    "        \"select current_account() as account, current_region() as region, current_role() as role, current_database() as db, current_schema() as sch\",\n",
    "    )\n",
    "    .load()\n",
    ")\n",
    "\n",
    "probe.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8437ab-c40e-4be2-93d8-5e4ad63da956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msg: string (nullable = false)\n",
      " |-- run_id: string (nullable = false)\n",
      " |-- ts_current: timestamp (nullable = true)\n",
      "\n",
      "+---------------+------+----------+\n",
      "|msg            |run_id|ts_current|\n",
      "+---------------+------+----------+\n",
      "|hello_snowflake|probe |NULL      |\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "\n",
    "data = [(\"hello_snowflake\", \"probe\", None)]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"msg\", StringType(), nullable=False),\n",
    "    StructField(\"run_id\", StringType(), nullable=False),\n",
    "    StructField(\"ts_current\", TimestampType(), nullable=True),\n",
    "])\n",
    "\n",
    "df_probe = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "df_probe.printSchema()\n",
    "df_probe.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc3bea4-fc16-4d44-88ee-bb15664d5fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas leídas: 1\n",
      "+---------------+------+----------+\n",
      "|MSG            |RUN_ID|TS_CURRENT|\n",
      "+---------------+------+----------+\n",
      "|hello_snowflake|probe |NULL      |\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_table = \"RAW._CONNECT_PROBE\"\n",
    "\n",
    "# Escribir\n",
    "(\n",
    "    df_probe.write\n",
    "    .format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\"dbtable\", target_table)\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")\n",
    "\n",
    "# Leer de vuelta\n",
    "df_back = (\n",
    "    spark.read\n",
    "    .format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\"dbtable\", target_table)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "print(\"Filas leídas:\", df_back.count())\n",
    "df_back.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5bccb0-6cab-482b-9b58-f67c2e488ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo local: /home/jovyan/work/datasets/trip-data/yellow_tripdata_2019-01.parquet\n",
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|1       |2019-01-01 00:46:40 |2019-01-01 00:53:20  |1.0            |1.5          |1.0       |N                 |151         |239         |1           |7.0        |0.5  |0.5    |1.65      |0.0         |0.3                  |9.95        |NULL                |NULL       |\n",
      "|1       |2019-01-01 00:59:47 |2019-01-01 01:18:59  |1.0            |2.6          |1.0       |N                 |239         |246         |1           |14.0       |0.5  |0.5    |1.0       |0.0         |0.3                  |16.3        |NULL                |NULL       |\n",
      "|2       |2018-12-21 13:48:30 |2018-12-21 13:52:40  |3.0            |0.0          |1.0       |N                 |236         |236         |1           |4.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |5.8         |NULL                |NULL       |\n",
      "|2       |2018-11-28 15:52:25 |2018-11-28 15:55:45  |5.0            |0.0          |1.0       |N                 |193         |193         |2           |3.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |7.55        |NULL                |NULL       |\n",
      "|2       |2018-11-28 15:56:57 |2018-11-28 15:58:33  |5.0            |0.0          |2.0       |N                 |193         |193         |2           |52.0       |0.0  |0.5    |0.0       |0.0         |0.3                  |55.55       |NULL                |NULL       |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, urllib.request\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# 1) Preparar carpeta local\n",
    "local_dir = \"/home/jovyan/work/datasets/trip-data\"\n",
    "pathlib.Path(local_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) Descarga de un archivo de prueba (enero 2019, yellow)\n",
    "remote = f\"{os.getenv('DATA_BASE_URL')}/yellow_tripdata_2019-01.parquet\"\n",
    "local  = f\"{local_dir}/yellow_tripdata_2019-01.parquet\"\n",
    "if not os.path.exists(local):\n",
    "    print(\"Descargando:\", remote)\n",
    "    urllib.request.urlretrieve(remote, local)\n",
    "\n",
    "# 3) Leer el Parquet desde el disco local (seekable)\n",
    "print(\"Leyendo local:\", local)\n",
    "df_probe_read = spark.read.parquet(local)\n",
    "df_probe_read.printSchema()\n",
    "df_probe_read.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf6c1f1-8042-4b29-90b4-f17a420c82f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas en RAW: 7696617\n",
      "+-----------------------+------------+-----------+------------+--------------------+\n",
      "|run_id                 |service_type|source_year|source_month|ingested_at_utc     |\n",
      "+-----------------------+------------+-----------+------------+--------------------+\n",
      "|manual_20251016T021100Z|yellow      |2019       |01          |2025-10-16T02:11:00Z|\n",
      "|manual_20251016T021100Z|yellow      |2019       |01          |2025-10-16T02:11:00Z|\n",
      "|manual_20251016T021100Z|yellow      |2019       |01          |2025-10-16T02:11:00Z|\n",
      "|manual_20251016T021100Z|yellow      |2019       |01          |2025-10-16T02:11:00Z|\n",
      "|manual_20251016T021100Z|yellow      |2019       |01          |2025-10-16T02:11:00Z|\n",
      "+-----------------------+------------+-----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "\n",
    "# 1) Normalizar columnas de tiempo a Spark `timestamp`\n",
    "df_fixed = (\n",
    "    df_probe_read\n",
    "    .withColumn(\"tpep_pickup_datetime\",  col(\"tpep_pickup_datetime\").cast(TimestampType()))\n",
    "    .withColumn(\"tpep_dropoff_datetime\", col(\"tpep_dropoff_datetime\").cast(TimestampType()))\n",
    ")\n",
    "\n",
    "# 2) Metadatos mínimos (lineage)\n",
    "run_id = os.getenv(\"RUN_ID\") or f\"manual_{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}\"\n",
    "df_raw = (\n",
    "    df_fixed\n",
    "    .withColumn(\"run_id\",          lit(run_id))\n",
    "    .withColumn(\"service_type\",    lit(\"yellow\"))\n",
    "    .withColumn(\"source_year\",     lit(\"2019\"))\n",
    "    .withColumn(\"source_month\",    lit(\"01\"))\n",
    "    .withColumn(\"ingested_at_utc\", lit(datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")))\n",
    ")\n",
    "\n",
    "# 3) Escribir en RAW y verificar\n",
    "target_table = \"RAW.TRIPS_YELLOW_2019_01\"\n",
    "\n",
    "(\n",
    "    df_raw.write\n",
    "    .format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\"dbtable\", target_table)\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")\n",
    "\n",
    "df_back = (\n",
    "    spark.read\n",
    "    .format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\"dbtable\", target_table)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "print(\"Filas en RAW:\", df_back.count())\n",
    "df_back.select(\"run_id\",\"service_type\",\"source_year\",\"source_month\",\"ingested_at_utc\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d6487e3-c580-4fce-8ab7-7d3ce957a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dia 01 -> inserted: 15469\n",
      "Dia 02 -> inserted: 19900\n",
      "Dia 03 -> inserted: 21931\n",
      "Dia 04 -> inserted: 23133\n",
      "Dia 05 -> inserted: 20832\n",
      "Dia 06 -> inserted: 18745\n",
      "Dia 07 -> inserted: 21368\n",
      "Dia 08 -> inserted: 21082\n",
      "Dia 09 -> inserted: 22977\n",
      "Dia 10 -> inserted: 24703\n",
      "Dia 11 -> inserted: 25666\n",
      "Dia 12 -> inserted: 21973\n",
      "Dia 13 -> inserted: 18507\n",
      "Dia 14 -> inserted: 21534\n",
      "Dia 15 -> inserted: 22453\n",
      "Dia 16 -> inserted: 23512\n",
      "Dia 17 -> inserted: 24640\n",
      "Dia 18 -> inserted: 23966\n",
      "Dia 19 -> inserted: 21318\n",
      "Dia 20 -> inserted: 16122\n",
      "Dia 21 -> inserted: 14341\n",
      "Dia 22 -> inserted: 21585\n",
      "Dia 23 -> inserted: 23074\n",
      "Dia 24 -> inserted: 23776\n",
      "Dia 25 -> inserted: 26062\n",
      "Dia 26 -> inserted: 23570\n",
      "Dia 27 -> inserted: 19355\n",
      "Dia 28 -> inserted: 21998\n",
      "Dia 29 -> inserted: 23165\n",
      "Dia 30 -> inserted: 22780\n",
      "Dia 31 -> inserted: 22568\n",
      "Tabla RAW destino: RAW.TRIPS_GREEN_2019_01\n",
      "Filas en RAW (GREEN 2019-01): 672105\n",
      "Total insertadas por loop: 672105\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, dayofmonth\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "\n",
    "target_table = \"RAW.TRIPS_GREEN_2019_01\"\n",
    "\n",
    "# 0) Preparar DF base (con timestamps normalizados y metadatos fijos del mes)\n",
    "run_id = os.getenv(\"RUN_ID\") or f\"manual_{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}\"\n",
    "df_base = (\n",
    "    spark.read.parquet(\"/home/jovyan/work/datasets/trip-data/green_tripdata_2019-01.parquet\")\n",
    "    .withColumn(\"lpep_pickup_datetime\",  col(\"lpep_pickup_datetime\").cast(TimestampType()))\n",
    "    .withColumn(\"lpep_dropoff_datetime\", col(\"lpep_dropoff_datetime\").cast(TimestampType()))\n",
    "    .withColumn(\"run_id\",          lit(run_id))\n",
    "    .withColumn(\"service_type\",    lit(\"green\"))\n",
    "    .withColumn(\"source_year\",     lit(\"2019\"))\n",
    "    .withColumn(\"source_month\",    lit(\"01\"))\n",
    "    .withColumn(\"ingested_at_utc\", lit(datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")))\n",
    ")\n",
    "\n",
    "# 1) Borrar/crear la tabla del mes (dejarla vacía) para asegurar un estado limpio\n",
    "#    - hacemos overwrite con 0 filas: limit(0) -> define el schema en Snowflake sin datos\n",
    "(\n",
    "    df_base.limit(0)\n",
    "    .write.format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\"dbtable\", target_table)\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")\n",
    "\n",
    "# 2) Escribir en micro-lotes por día (append), con paralelismo conservador\n",
    "dias = list(range(1, 32))  # 1..31\n",
    "total_insertadas = 0\n",
    "\n",
    "for d in dias:\n",
    "    df_day = (\n",
    "        df_base\n",
    "        .filter(dayofmonth(col(\"lpep_pickup_datetime\")) == d)\n",
    "        .coalesce(2)                       # pocos archivos por día\n",
    "    )\n",
    "    cnt = df_day.count()\n",
    "    if cnt == 0:\n",
    "        continue\n",
    "\n",
    "    (\n",
    "        df_day.write.format(\"snowflake\")\n",
    "        .options(**sfOptions)\n",
    "        .option(\"dbtable\", target_table)\n",
    "        .option(\"parallelism\", \"2\")        # pocas conexiones\n",
    "        .option(\"usestagingtable\", \"off\")  # reduce pasos adicionales\n",
    "        .mode(\"append\")\n",
    "        .save()\n",
    "    )\n",
    "\n",
    "    total_insertadas += cnt\n",
    "    print(f\"Dia {d:02d} -> inserted: {cnt}\")\n",
    "\n",
    "# 3) Verificar conteo final en Snowflake\n",
    "df_back = (\n",
    "    spark.read.format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\"dbtable\", target_table)\n",
    "    .load()\n",
    ")\n",
    "print(\"Tabla RAW destino:\", target_table)\n",
    "print(\"Filas en RAW (GREEN 2019-01):\", df_back.count())\n",
    "print(\"Total insertadas por loop:\", total_insertadas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "340bbc84-b1fa-4fa7-9a03-9d70153d6709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperadas (parquet): 7696617\n",
      "[yellow 2019-01] 2019-01-01 00:00:00..2019-01-02 00:00:00 -> inserted: 189432\n",
      "[yellow 2019-01] 2019-01-02 00:00:00..2019-01-03 00:00:00 -> inserted: 198737\n",
      "[WARN] intento 1/3 falló (rango 2019-01-03 00:00:00..2019-01-04 00:00:00): An error occurred while calling o5230.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2019-01] 2019-01-03 00:00:00..2019-01-04 00:00:00 -> inserted: 223965\n",
      "[yellow 2019-01] 2019-01-04 00:00:00..2019-01-05 00:00:00 -> inserted: 236089\n",
      "[yellow 2019-01] 2019-01-05 00:00:00..2019-01-06 00:00:00 -> inserted: 236506\n",
      "[yellow 2019-01] 2019-01-06 00:00:00..2019-01-07 00:00:00 -> inserted: 208823\n",
      "[yellow 2019-01] 2019-01-07 00:00:00..2019-01-08 00:00:00 -> inserted: 228816\n",
      "[WARN] intento 1/3 falló (rango 2019-01-08 00:00:00..2019-01-09 00:00:00): An error occurred while calling o5363.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2019-01] 2019-01-08 00:00:00..2019-01-09 00:00:00 -> inserted: 237310\n",
      "[yellow 2019-01] 2019-01-09 00:00:00..2019-01-10 00:00:00 -> inserted: 255868\n",
      "[WARN] intento 1/3 falló (rango 2019-01-10 00:00:00..2019-01-11 00:00:00): An error occurred while calling o5427.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2019-01] 2019-01-10 00:00:00..2019-01-11 00:00:00 -> inserted: 281863\n",
      "[yellow 2019-01] 2019-01-11 00:00:00..2019-01-12 00:00:00 -> inserted: 291714\n",
      "[yellow 2019-01] 2019-01-12 00:00:00..2019-01-13 00:00:00 -> inserted: 265115\n",
      "[yellow 2019-01] 2019-01-13 00:00:00..2019-01-14 00:00:00 -> inserted: 227502\n",
      "[yellow 2019-01] 2019-01-14 00:00:00..2019-01-15 00:00:00 -> inserted: 245082\n",
      "[WARN] intento 1/3 falló (rango 2019-01-15 00:00:00..2019-01-16 00:00:00): An error occurred while calling o5560.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.createJDBCConnection(ServerConnection.scala:279)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.getServerConnection(ServerConnection.scala:130)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.getConnector(SnowflakeJDBCWrapper.scala:111)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:210)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2019-01] 2019-01-15 00:00:00..2019-01-16 00:00:00 -> inserted: 267370\n",
      "[yellow 2019-01] 2019-01-16 00:00:00..2019-01-17 00:00:00 -> inserted: 272699\n",
      "[WARN] intento 1/3 falló (rango 2019-01-17 00:00:00..2019-01-18 00:00:00): An error occurred while calling o5623.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2019-01] 2019-01-17 00:00:00..2019-01-18 00:00:00 -> inserted: 284580\n",
      "[yellow 2019-01] 2019-01-18 00:00:00..2019-01-19 00:00:00 -> inserted: 266848\n",
      "[yellow 2019-01] 2019-01-19 00:00:00..2019-01-20 00:00:00 -> inserted: 236365\n",
      "[yellow 2019-01] 2019-01-20 00:00:00..2019-01-21 00:00:00 -> inserted: 203114\n",
      "[yellow 2019-01] 2019-01-21 00:00:00..2019-01-22 00:00:00 -> inserted: 192826\n",
      "[yellow 2019-01] 2019-01-22 00:00:00..2019-01-23 00:00:00 -> inserted: 255178\n",
      "[yellow 2019-01] 2019-01-23 00:00:00..2019-01-24 00:00:00 -> inserted: 261151\n",
      "[yellow 2019-01] 2019-01-24 00:00:00..2019-01-25 00:00:00 -> inserted: 281959\n",
      "[WARN] intento 1/3 falló (rango 2019-01-25 00:00:00..2019-01-26 00:00:00): An error occurred while calling o5825.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2019-01] 2019-01-25 00:00:00..2019-01-26 00:00:00 -> inserted: 292499\n",
      "[yellow 2019-01] 2019-01-26 00:00:00..2019-01-27 00:00:00 -> inserted: 271993\n",
      "[WARN] intento 1/3 falló (rango 2019-01-27 00:00:00..2019-01-28 00:00:00): An error occurred while calling o5888.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2019-01] 2019-01-27 00:00:00..2019-01-28 00:00:00 -> inserted: 220451\n",
      "[yellow 2019-01] 2019-01-28 00:00:00..2019-01-29 00:00:00 -> inserted: 241040\n",
      "[WARN] intento 1/3 falló (rango 2019-01-29 00:00:00..2019-01-30 00:00:00): An error occurred while calling o5951.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2019-01] 2019-01-29 00:00:00..2019-01-30 00:00:00 -> inserted: 259786\n",
      "[yellow 2019-01] 2019-01-30 00:00:00..2019-01-31 00:00:00 -> inserted: 276774\n",
      "[yellow 2019-01] 2019-01-31 00:00:00..2019-02-01 00:00:00 -> inserted: 284625\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2019_01\n",
      "Filas en RAW (YELLOW 2019-01): 7696080\n",
      "Esperadas (parquet): 7696617\n",
      "Insertadas por loop: 7696080\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import os, time\n",
    "\n",
    "svc = \"yellow\"\n",
    "YEAR, mm = \"2019\", \"01\"\n",
    "pcol = \"tpep_pickup_datetime\"\n",
    "target_table = f\"RAW.TRIPS_{svc.upper()}_{YEAR}_{mm}\"\n",
    "\n",
    "# 0) Leer parquet local y normalizar\n",
    "df_month = spark.read.parquet(f\"/home/jovyan/work/datasets/trip-data/yellow_tripdata_{YEAR}-{mm}.parquet\") \\\n",
    "    .withColumn(\"tpep_pickup_datetime\",  col(\"tpep_pickup_datetime\").cast(TimestampType())) \\\n",
    "    .withColumn(\"tpep_dropoff_datetime\", col(\"tpep_dropoff_datetime\").cast(TimestampType()))\n",
    "\n",
    "expected = df_month.count()\n",
    "print(\"Esperadas (parquet):\", expected)\n",
    "\n",
    "# 1) Metadatos consistentes (incluye source_path)\n",
    "run_id = os.getenv(\"RUN_ID\") or f\"manual_{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}\"\n",
    "remote_month_path = f\"{os.getenv('DATA_BASE_URL')}/yellow_tripdata_{YEAR}-{mm}.parquet\"\n",
    "\n",
    "df_base = df_month \\\n",
    "    .withColumn(\"run_id\",          lit(run_id)) \\\n",
    "    .withColumn(\"service_type\",    lit(svc)) \\\n",
    "    .withColumn(\"source_year\",     lit(YEAR)) \\\n",
    "    .withColumn(\"source_month\",    lit(mm)) \\\n",
    "    .withColumn(\"source_path\",     lit(remote_month_path)) \\\n",
    "    .withColumn(\"ingested_at_utc\", lit(datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")))\n",
    "\n",
    "# 2) TRUNCATE al inicio para empezar de cero (y fijar schema)\n",
    "(\n",
    "    df_base.limit(0).write.format(\"snowflake\")\n",
    "    .options(**sfOptions)\n",
    "    .option(\"dbtable\", target_table)\n",
    "    .option(\"preactions\", f\"TRUNCATE TABLE {target_table}\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")\n",
    "\n",
    "def write_day_range(df_day, lo, hi, tries=3):\n",
    "    \"\"\"Borra [lo,hi) en Snowflake y escribe ese rango; ambos rangos en NTZ.\"\"\"\n",
    "    pre_sql = (\n",
    "        f\"DELETE FROM {target_table} \"\n",
    "        f\"WHERE {pcol} >= TO_TIMESTAMP_NTZ('{lo}') \"\n",
    "        f\"  AND {pcol} <  TO_TIMESTAMP_NTZ('{hi}')\"\n",
    "    )\n",
    "    last = None\n",
    "    for a in range(1, tries+1):\n",
    "        try:\n",
    "            (df_day.write.format(\"snowflake\")\n",
    "             .options(**sfOptions)\n",
    "             .option(\"dbtable\", target_table)\n",
    "             .option(\"parallelism\", \"1\")\n",
    "             .option(\"usestagingtable\", \"off\")\n",
    "             .option(\"support_share_connection\", \"false\")\n",
    "             .option(\"preactions\", pre_sql)\n",
    "             .mode(\"append\")\n",
    "             .save())\n",
    "            return\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            print(f\"[WARN] intento {a}/{tries} falló (rango {lo}..{hi}): {e}\")\n",
    "            time.sleep(5)\n",
    "    raise last\n",
    "\n",
    "# 3) Cargar por rangos exactos día a día (Spark también filtra por [lo,hi))\n",
    "inserted_total = 0\n",
    "for d in range(1, 32):\n",
    "    day_dt  = datetime.strptime(f\"{YEAR}-{mm}-{d:02d} 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    next_dt = day_dt + timedelta(days=1)\n",
    "    lo = day_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    hi = next_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    part = df_base.filter((col(pcol) >= lo) & (col(pcol) < hi)).coalesce(1)\n",
    "    cnt = part.count()\n",
    "    if cnt == 0:\n",
    "        continue\n",
    "\n",
    "    write_day_range(part, lo, hi)\n",
    "    inserted_total += cnt\n",
    "    print(f\"[{svc} {YEAR}-{mm}] {lo}..{hi} -> inserted: {cnt}\")\n",
    "\n",
    "# 4) Verificación final\n",
    "df_back = (spark.read.format(\"snowflake\").options(**sfOptions).option(\"dbtable\", target_table).load())\n",
    "final_cnt = df_back.count()\n",
    "print(\"Tabla RAW destino:\", target_table)\n",
    "print(\"Filas en RAW (YELLOW 2019-01):\", final_cnt)\n",
    "print(\"Esperadas (parquet):\", expected)\n",
    "print(\"Insertadas por loop:\", inserted_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4093d2c0-1dac-4cae-956d-6a4de00b4d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[yellow 2015-01] 2015-01-01 00:00:00..2015-01-02 00:00:00 -> inserted: 382014\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18187.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-01] 2015-01-02 00:00:00..2015-01-03 00:00:00 -> inserted: 345299\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18228.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-01] 2015-01-03 00:00:00..2015-01-04 00:00:00 -> inserted: 406771\n",
      "[yellow 2015-01] 2015-01-04 00:00:00..2015-01-05 00:00:00 -> inserted: 328848\n",
      "[yellow 2015-01] 2015-01-05 00:00:00..2015-01-06 00:00:00 -> inserted: 362927\n",
      "[yellow 2015-01] 2015-01-06 00:00:00..2015-01-07 00:00:00 -> inserted: 383902\n",
      "[yellow 2015-01] 2015-01-07 00:00:00..2015-01-08 00:00:00 -> inserted: 429309\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18361.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-01] 2015-01-08 00:00:00..2015-01-09 00:00:00 -> inserted: 450601\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18401.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-01] 2015-01-09 00:00:00..2015-01-10 00:00:00 -> inserted: 447563\n",
      "[yellow 2015-01] 2015-01-10 00:00:00..2015-01-11 00:00:00 -> inserted: 515236\n",
      "[yellow 2015-01] 2015-01-11 00:00:00..2015-01-12 00:00:00 -> inserted: 419436\n",
      "[yellow 2015-01] 2015-01-12 00:00:00..2015-01-13 00:00:00 -> inserted: 396038\n",
      "[yellow 2015-01] 2015-01-13 00:00:00..2015-01-14 00:00:00 -> inserted: 448149\n",
      "[yellow 2015-01] 2015-01-14 00:00:00..2015-01-15 00:00:00 -> inserted: 442184\n",
      "[yellow 2015-01] 2015-01-15 00:00:00..2015-01-16 00:00:00 -> inserted: 450751\n",
      "[yellow 2015-01] 2015-01-16 00:00:00..2015-01-17 00:00:00 -> inserted: 477847\n",
      "[yellow 2015-01] 2015-01-17 00:00:00..2015-01-18 00:00:00 -> inserted: 476571\n",
      "[yellow 2015-01] 2015-01-18 00:00:00..2015-01-19 00:00:00 -> inserted: 426908\n",
      "[yellow 2015-01] 2015-01-19 00:00:00..2015-01-20 00:00:00 -> inserted: 342502\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18672.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-01] 2015-01-20 00:00:00..2015-01-21 00:00:00 -> inserted: 405190\n",
      "[yellow 2015-01] 2015-01-21 00:00:00..2015-01-22 00:00:00 -> inserted: 431211\n",
      "[yellow 2015-01] 2015-01-22 00:00:00..2015-01-23 00:00:00 -> inserted: 451868\n",
      "[yellow 2015-01] 2015-01-23 00:00:00..2015-01-24 00:00:00 -> inserted: 472146\n",
      "[yellow 2015-01] 2015-01-24 00:00:00..2015-01-25 00:00:00 -> inserted: 460303\n",
      "[yellow 2015-01] 2015-01-25 00:00:00..2015-01-26 00:00:00 -> inserted: 407447\n",
      "[yellow 2015-01] 2015-01-26 00:00:00..2015-01-27 00:00:00 -> inserted: 230049\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18850.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:143)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-01] 2015-01-27 00:00:00..2015-01-28 00:00:00 -> inserted: 135460\n",
      "[yellow 2015-01] 2015-01-28 00:00:00..2015-01-29 00:00:00 -> inserted: 379945\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18914.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-01] 2015-01-29 00:00:00..2015-01-30 00:00:00 -> inserted: 431647\n",
      "[yellow 2015-01] 2015-01-30 00:00:00..2015-01-31 00:00:00 -> inserted: 483118\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o18977.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-01] 2015-01-31 00:00:00..2015-02-01 00:00:00 -> inserted: 519795\n",
      "\n",
      "=== RESUMEN YELLOW 2015-01 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_01\n",
      "Esperadas (parquet): 12741035\n",
      "Insertadas por loop (sin NULL): 12741035\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 12741035  --> OK\n",
      "\n",
      "[yellow 2015-02] 2015-02-01 00:00:00..2015-02-02 00:00:00 -> inserted: 422943\n",
      "[yellow 2015-02] 2015-02-02 00:00:00..2015-02-03 00:00:00 -> inserted: 336627\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o19147.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-02] 2015-02-03 00:00:00..2015-02-04 00:00:00 -> inserted: 420848\n",
      "[yellow 2015-02] 2015-02-04 00:00:00..2015-02-05 00:00:00 -> inserted: 415249\n",
      "[yellow 2015-02] 2015-02-05 00:00:00..2015-02-06 00:00:00 -> inserted: 459398\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o19233.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-02] 2015-02-06 00:00:00..2015-02-07 00:00:00 -> inserted: 476736\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o19273.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-02] 2015-02-07 00:00:00..2015-02-08 00:00:00 -> inserted: 485251\n",
      "[yellow 2015-02] 2015-02-08 00:00:00..2015-02-09 00:00:00 -> inserted: 410266\n",
      "[yellow 2015-02] 2015-02-09 00:00:00..2015-02-10 00:00:00 -> inserted: 380916\n",
      "[yellow 2015-02] 2015-02-10 00:00:00..2015-02-11 00:00:00 -> inserted: 424216\n",
      "[yellow 2015-02] 2015-02-11 00:00:00..2015-02-12 00:00:00 -> inserted: 446859\n",
      "[yellow 2015-02] 2015-02-12 00:00:00..2015-02-13 00:00:00 -> inserted: 463330\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o19429.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-02] 2015-02-13 00:00:00..2015-02-14 00:00:00 -> inserted: 485898\n",
      "[yellow 2015-02] 2015-02-14 00:00:00..2015-02-15 00:00:00 -> inserted: 501208\n",
      "[yellow 2015-02] 2015-02-15 00:00:00..2015-02-16 00:00:00 -> inserted: 458982\n",
      "[yellow 2015-02] 2015-02-16 00:00:00..2015-02-17 00:00:00 -> inserted: 412495\n",
      "[yellow 2015-02] 2015-02-17 00:00:00..2015-02-18 00:00:00 -> inserted: 393985\n",
      "[yellow 2015-02] 2015-02-18 00:00:00..2015-02-19 00:00:00 -> inserted: 436231\n",
      "[yellow 2015-02] 2015-02-19 00:00:00..2015-02-20 00:00:00 -> inserted: 477303\n",
      "[yellow 2015-02] 2015-02-20 00:00:00..2015-02-21 00:00:00 -> inserted: 498591\n",
      "[yellow 2015-02] 2015-02-21 00:00:00..2015-02-22 00:00:00 -> inserted: 455121\n",
      "[yellow 2015-02] 2015-02-22 00:00:00..2015-02-23 00:00:00 -> inserted: 398963\n",
      "[yellow 2015-02] 2015-02-23 00:00:00..2015-02-24 00:00:00 -> inserted: 431519\n",
      "[yellow 2015-02] 2015-02-24 00:00:00..2015-02-25 00:00:00 -> inserted: 448146\n",
      "[yellow 2015-02] 2015-02-25 00:00:00..2015-02-26 00:00:00 -> inserted: 443927\n",
      "[yellow 2015-02] 2015-02-26 00:00:00..2015-02-27 00:00:00 -> inserted: 471374\n",
      "[yellow 2015-02] 2015-02-27 00:00:00..2015-02-28 00:00:00 -> inserted: 486694\n",
      "[yellow 2015-02] 2015-02-28 00:00:00..2015-03-01 00:00:00 -> inserted: 499318\n",
      "\n",
      "=== RESUMEN YELLOW 2015-02 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_02\n",
      "Esperadas (parquet): 12442394\n",
      "Insertadas por loop (sin NULL): 12442394\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 12442394  --> OK\n",
      "\n",
      "[yellow 2015-03] 2015-03-01 00:00:00..2015-03-02 00:00:00 -> inserted: 385075\n",
      "[yellow 2015-03] 2015-03-02 00:00:00..2015-03-03 00:00:00 -> inserted: 388260\n",
      "[yellow 2015-03] 2015-03-03 00:00:00..2015-03-04 00:00:00 -> inserted: 397382\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o19967.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-03] 2015-03-04 00:00:00..2015-03-05 00:00:00 -> inserted: 435473\n",
      "[yellow 2015-03] 2015-03-05 00:00:00..2015-03-06 00:00:00 -> inserted: 366224\n",
      "[yellow 2015-03] 2015-03-06 00:00:00..2015-03-07 00:00:00 -> inserted: 446537\n",
      "[yellow 2015-03] 2015-03-07 00:00:00..2015-03-08 00:00:00 -> inserted: 504034\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20076.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-03] 2015-03-08 00:00:00..2015-03-09 00:00:00 -> inserted: 411751\n",
      "[yellow 2015-03] 2015-03-09 00:00:00..2015-03-10 00:00:00 -> inserted: 391702\n",
      "[yellow 2015-03] 2015-03-10 00:00:00..2015-03-11 00:00:00 -> inserted: 413664\n",
      "[yellow 2015-03] 2015-03-11 00:00:00..2015-03-12 00:00:00 -> inserted: 427985\n",
      "[yellow 2015-03] 2015-03-12 00:00:00..2015-03-13 00:00:00 -> inserted: 461339\n",
      "[yellow 2015-03] 2015-03-13 00:00:00..2015-03-14 00:00:00 -> inserted: 476607\n",
      "[yellow 2015-03] 2015-03-14 00:00:00..2015-03-15 00:00:00 -> inserted: 496319\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20254.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-03] 2015-03-15 00:00:00..2015-03-16 00:00:00 -> inserted: 418671\n",
      "[yellow 2015-03] 2015-03-16 00:00:00..2015-03-17 00:00:00 -> inserted: 374536\n",
      "[yellow 2015-03] 2015-03-17 00:00:00..2015-03-18 00:00:00 -> inserted: 413092\n",
      "[yellow 2015-03] 2015-03-18 00:00:00..2015-03-19 00:00:00 -> inserted: 452660\n",
      "[yellow 2015-03] 2015-03-19 00:00:00..2015-03-20 00:00:00 -> inserted: 451613\n",
      "[yellow 2015-03] 2015-03-20 00:00:00..2015-03-21 00:00:00 -> inserted: 457915\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20409.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-03] 2015-03-21 00:00:00..2015-03-22 00:00:00 -> inserted: 467883\n",
      "[yellow 2015-03] 2015-03-22 00:00:00..2015-03-23 00:00:00 -> inserted: 428878\n",
      "[yellow 2015-03] 2015-03-23 00:00:00..2015-03-24 00:00:00 -> inserted: 389979\n",
      "[yellow 2015-03] 2015-03-24 00:00:00..2015-03-25 00:00:00 -> inserted: 411739\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20518.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1343)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommand(SnowflakeFileTransferAgent.java:915)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.<init>(SnowflakeFileTransferAgent.java:890)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent$lzycompute(SFInternalStage.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent(SFInternalStage.scala:43)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials$lzycompute(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds$lzycompute(SFInternalStage.scala:127)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds(SFInternalStage.scala:116)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.getStageInfo(CloudStorageOperations.scala:1348)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload(CloudStorageOperations.scala:555)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload$(CloudStorageOperations.scala:550)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.upload(CloudStorageOperations.scala:1329)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: net.snowflake.client.core.SFException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null., sql state = XX000\n",
      "\tat net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:431)\n",
      "\tat net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:502)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1333)\n",
      "\t... 56 more\n",
      "\n",
      "[yellow 2015-03] 2015-03-25 00:00:00..2015-03-26 00:00:00 -> inserted: 426728\n",
      "[yellow 2015-03] 2015-03-26 00:00:00..2015-03-27 00:00:00 -> inserted: 427236\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20582.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-03] 2015-03-27 00:00:00..2015-03-28 00:00:00 -> inserted: 465199\n",
      "[yellow 2015-03] 2015-03-28 00:00:00..2015-03-29 00:00:00 -> inserted: 510173\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20645.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-03] 2015-03-29 00:00:00..2015-03-30 00:00:00 -> inserted: 424130\n",
      "[yellow 2015-03] 2015-03-30 00:00:00..2015-03-31 00:00:00 -> inserted: 390638\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20708.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1343)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommand(SnowflakeFileTransferAgent.java:915)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.<init>(SnowflakeFileTransferAgent.java:890)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent$lzycompute(SFInternalStage.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent(SFInternalStage.scala:43)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageInfo$lzycompute(SFInternalStage.scala:59)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageInfo(SFInternalStage.scala:59)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageType$lzycompute(SFInternalStage.scala:67)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageType(SFInternalStage.scala:66)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorageOperations$.createStorageClientFromStage(CloudStorageOperations.scala:239)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorageOperations$.createStorageClient(CloudStorageOperations.scala:370)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:216)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: net.snowflake.client.core.SFException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null., sql state = XX000\n",
      "\tat net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:431)\n",
      "\tat net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:502)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1333)\n",
      "\t... 54 more\n",
      "\n",
      "[yellow 2015-03] 2015-03-31 00:00:00..2015-04-01 00:00:00 -> inserted: 429529\n",
      "\n",
      "=== RESUMEN YELLOW 2015-03 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_03\n",
      "Esperadas (parquet): 13342951\n",
      "Insertadas por loop (sin NULL): 13342951\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 13342951  --> OK\n",
      "\n",
      "[yellow 2015-04] 2015-04-01 00:00:00..2015-04-02 00:00:00 -> inserted: 439865\n",
      "[yellow 2015-04] 2015-04-02 00:00:00..2015-04-03 00:00:00 -> inserted: 443987\n",
      "[yellow 2015-04] 2015-04-03 00:00:00..2015-04-04 00:00:00 -> inserted: 443759\n",
      "[yellow 2015-04] 2015-04-04 00:00:00..2015-04-05 00:00:00 -> inserted: 439978\n",
      "[yellow 2015-04] 2015-04-05 00:00:00..2015-04-06 00:00:00 -> inserted: 377318\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o20948.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-04] 2015-04-06 00:00:00..2015-04-07 00:00:00 -> inserted: 375397\n",
      "[yellow 2015-04] 2015-04-07 00:00:00..2015-04-08 00:00:00 -> inserted: 425546\n",
      "[yellow 2015-04] 2015-04-08 00:00:00..2015-04-09 00:00:00 -> inserted: 443134\n",
      "[yellow 2015-04] 2015-04-09 00:00:00..2015-04-10 00:00:00 -> inserted: 460152\n",
      "[yellow 2015-04] 2015-04-10 00:00:00..2015-04-11 00:00:00 -> inserted: 467725\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o21080.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-04] 2015-04-11 00:00:00..2015-04-12 00:00:00 -> inserted: 473564\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o21120.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-04] 2015-04-12 00:00:00..2015-04-13 00:00:00 -> inserted: 407202\n",
      "[yellow 2015-04] 2015-04-13 00:00:00..2015-04-14 00:00:00 -> inserted: 376851\n",
      "[yellow 2015-04] 2015-04-14 00:00:00..2015-04-15 00:00:00 -> inserted: 411603\n",
      "[yellow 2015-04] 2015-04-15 00:00:00..2015-04-16 00:00:00 -> inserted: 426875\n",
      "[yellow 2015-04] 2015-04-16 00:00:00..2015-04-17 00:00:00 -> inserted: 451797\n",
      "[yellow 2015-04] 2015-04-17 00:00:00..2015-04-18 00:00:00 -> inserted: 468981\n",
      "[yellow 2015-04] 2015-04-18 00:00:00..2015-04-19 00:00:00 -> inserted: 500718\n",
      "[yellow 2015-04] 2015-04-19 00:00:00..2015-04-20 00:00:00 -> inserted: 445652\n",
      "[yellow 2015-04] 2015-04-20 00:00:00..2015-04-21 00:00:00 -> inserted: 396990\n",
      "[yellow 2015-04] 2015-04-21 00:00:00..2015-04-22 00:00:00 -> inserted: 425837\n",
      "[yellow 2015-04] 2015-04-22 00:00:00..2015-04-23 00:00:00 -> inserted: 432212\n",
      "[yellow 2015-04] 2015-04-23 00:00:00..2015-04-24 00:00:00 -> inserted: 463219\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o21414.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-04] 2015-04-24 00:00:00..2015-04-25 00:00:00 -> inserted: 473821\n",
      "[yellow 2015-04] 2015-04-25 00:00:00..2015-04-26 00:00:00 -> inserted: 489280\n",
      "[yellow 2015-04] 2015-04-26 00:00:00..2015-04-27 00:00:00 -> inserted: 424420\n",
      "[yellow 2015-04] 2015-04-27 00:00:00..2015-04-28 00:00:00 -> inserted: 393256\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o21523.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-04] 2015-04-28 00:00:00..2015-04-29 00:00:00 -> inserted: 411479\n",
      "[yellow 2015-04] 2015-04-29 00:00:00..2015-04-30 00:00:00 -> inserted: 427268\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o21586.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeAsyncQuery(SnowflakePreparedStatementV1.java:189)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryAsyncInterruptibly$1(SnowflakeJDBCWrapper.scala:228)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-04] 2015-04-30 00:00:00..2015-05-01 00:00:00 -> inserted: 445872\n",
      "\n",
      "=== RESUMEN YELLOW 2015-04 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_04\n",
      "Esperadas (parquet): 13063758\n",
      "Insertadas por loop (sin NULL): 13063758\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 13063758  --> OK\n",
      "\n",
      "[yellow 2015-05] 2015-05-01 00:00:00..2015-05-02 00:00:00 -> inserted: 461313\n",
      "[yellow 2015-05] 2015-05-02 00:00:00..2015-05-03 00:00:00 -> inserted: 507378\n",
      "[yellow 2015-05] 2015-05-03 00:00:00..2015-05-04 00:00:00 -> inserted: 434671\n",
      "[yellow 2015-05] 2015-05-04 00:00:00..2015-05-05 00:00:00 -> inserted: 390263\n",
      "[yellow 2015-05] 2015-05-05 00:00:00..2015-05-06 00:00:00 -> inserted: 432452\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o21825.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-05] 2015-05-06 00:00:00..2015-05-07 00:00:00 -> inserted: 444948\n",
      "[yellow 2015-05] 2015-05-07 00:00:00..2015-05-08 00:00:00 -> inserted: 442222\n",
      "[yellow 2015-05] 2015-05-08 00:00:00..2015-05-09 00:00:00 -> inserted: 449020\n",
      "[yellow 2015-05] 2015-05-09 00:00:00..2015-05-10 00:00:00 -> inserted: 469017\n",
      "[yellow 2015-05] 2015-05-10 00:00:00..2015-05-11 00:00:00 -> inserted: 405427\n",
      "[yellow 2015-05] 2015-05-11 00:00:00..2015-05-12 00:00:00 -> inserted: 395280\n",
      "[yellow 2015-05] 2015-05-12 00:00:00..2015-05-13 00:00:00 -> inserted: 424512\n",
      "[yellow 2015-05] 2015-05-13 00:00:00..2015-05-14 00:00:00 -> inserted: 439371\n",
      "[yellow 2015-05] 2015-05-14 00:00:00..2015-05-15 00:00:00 -> inserted: 439936\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o22049.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-05] 2015-05-15 00:00:00..2015-05-16 00:00:00 -> inserted: 457541\n",
      "[yellow 2015-05] 2015-05-16 00:00:00..2015-05-17 00:00:00 -> inserted: 479580\n",
      "[yellow 2015-05] 2015-05-17 00:00:00..2015-05-18 00:00:00 -> inserted: 423198\n",
      "[yellow 2015-05] 2015-05-18 00:00:00..2015-05-19 00:00:00 -> inserted: 403641\n",
      "[yellow 2015-05] 2015-05-19 00:00:00..2015-05-20 00:00:00 -> inserted: 432943\n",
      "[yellow 2015-05] 2015-05-20 00:00:00..2015-05-21 00:00:00 -> inserted: 441232\n",
      "[yellow 2015-05] 2015-05-21 00:00:00..2015-05-22 00:00:00 -> inserted: 446819\n",
      "[yellow 2015-05] 2015-05-22 00:00:00..2015-05-23 00:00:00 -> inserted: 419629\n",
      "[yellow 2015-05] 2015-05-23 00:00:00..2015-05-24 00:00:00 -> inserted: 383363\n",
      "[yellow 2015-05] 2015-05-24 00:00:00..2015-05-25 00:00:00 -> inserted: 336652\n",
      "[yellow 2015-05] 2015-05-25 00:00:00..2015-05-26 00:00:00 -> inserted: 301706\n",
      "[yellow 2015-05] 2015-05-26 00:00:00..2015-05-27 00:00:00 -> inserted: 387134\n",
      "[yellow 2015-05] 2015-05-27 00:00:00..2015-05-28 00:00:00 -> inserted: 415919\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o22365.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:143)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-05] 2015-05-28 00:00:00..2015-05-29 00:00:00 -> inserted: 432112\n",
      "[yellow 2015-05] 2015-05-29 00:00:00..2015-05-30 00:00:00 -> inserted: 441299\n",
      "[yellow 2015-05] 2015-05-30 00:00:00..2015-05-31 00:00:00 -> inserted: 451080\n",
      "[yellow 2015-05] 2015-05-31 00:00:00..2015-06-01 00:00:00 -> inserted: 368019\n",
      "\n",
      "=== RESUMEN YELLOW 2015-05 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_05\n",
      "Esperadas (parquet): 13157677\n",
      "Insertadas por loop (sin NULL): 13157677\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 13157677  --> OK\n",
      "\n",
      "[WARN] truncate RAW.TRIPS_YELLOW_2015_06: An error occurred while calling o22536.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:255)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-06] 2015-06-01 00:00:00..2015-06-02 00:00:00 -> inserted: 400833\n",
      "[yellow 2015-06] 2015-06-02 00:00:00..2015-06-03 00:00:00 -> inserted: 419994\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o22606.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.createJDBCConnection(ServerConnection.scala:279)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.getServerConnection(ServerConnection.scala:130)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.getConnector(SnowflakeJDBCWrapper.scala:111)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:210)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-06] 2015-06-03 00:00:00..2015-06-04 00:00:00 -> inserted: 425776\n",
      "[yellow 2015-06] 2015-06-04 00:00:00..2015-06-05 00:00:00 -> inserted: 444543\n",
      "[yellow 2015-06] 2015-06-05 00:00:00..2015-06-06 00:00:00 -> inserted: 451185\n",
      "[yellow 2015-06] 2015-06-06 00:00:00..2015-06-07 00:00:00 -> inserted: 449804\n",
      "[yellow 2015-06] 2015-06-07 00:00:00..2015-06-08 00:00:00 -> inserted: 402188\n",
      "[yellow 2015-06] 2015-06-08 00:00:00..2015-06-09 00:00:00 -> inserted: 391087\n",
      "[yellow 2015-06] 2015-06-09 00:00:00..2015-06-10 00:00:00 -> inserted: 409188\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o22784.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-06] 2015-06-10 00:00:00..2015-06-11 00:00:00 -> inserted: 424356\n",
      "[yellow 2015-06] 2015-06-11 00:00:00..2015-06-12 00:00:00 -> inserted: 439869\n",
      "[yellow 2015-06] 2015-06-12 00:00:00..2015-06-13 00:00:00 -> inserted: 443026\n",
      "[yellow 2015-06] 2015-06-13 00:00:00..2015-06-14 00:00:00 -> inserted: 428004\n",
      "[yellow 2015-06] 2015-06-14 00:00:00..2015-06-15 00:00:00 -> inserted: 382037\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o22916.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-06] 2015-06-15 00:00:00..2015-06-16 00:00:00 -> inserted: 374859\n",
      "[yellow 2015-06] 2015-06-16 00:00:00..2015-06-17 00:00:00 -> inserted: 400518\n",
      "[yellow 2015-06] 2015-06-17 00:00:00..2015-06-18 00:00:00 -> inserted: 425743\n",
      "[yellow 2015-06] 2015-06-18 00:00:00..2015-06-19 00:00:00 -> inserted: 429386\n",
      "[yellow 2015-06] 2015-06-19 00:00:00..2015-06-20 00:00:00 -> inserted: 436303\n",
      "[yellow 2015-06] 2015-06-20 00:00:00..2015-06-21 00:00:00 -> inserted: 413866\n",
      "[yellow 2015-06] 2015-06-21 00:00:00..2015-06-22 00:00:00 -> inserted: 366158\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o23094.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-06] 2015-06-22 00:00:00..2015-06-23 00:00:00 -> inserted: 374849\n",
      "[yellow 2015-06] 2015-06-23 00:00:00..2015-06-24 00:00:00 -> inserted: 406139\n",
      "[yellow 2015-06] 2015-06-24 00:00:00..2015-06-25 00:00:00 -> inserted: 411370\n",
      "[yellow 2015-06] 2015-06-25 00:00:00..2015-06-26 00:00:00 -> inserted: 419739\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o23204.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-06] 2015-06-26 00:00:00..2015-06-27 00:00:00 -> inserted: 425774\n",
      "[yellow 2015-06] 2015-06-27 00:00:00..2015-06-28 00:00:00 -> inserted: 445861\n",
      "[yellow 2015-06] 2015-06-28 00:00:00..2015-06-29 00:00:00 -> inserted: 348433\n",
      "[yellow 2015-06] 2015-06-29 00:00:00..2015-06-30 00:00:00 -> inserted: 359808\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o23313.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-06] 2015-06-30 00:00:00..2015-07-01 00:00:00 -> inserted: 374240\n",
      "\n",
      "=== RESUMEN YELLOW 2015-06 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_06\n",
      "Esperadas (parquet): 12324936\n",
      "Insertadas por loop (sin NULL): 12324936\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 12324936  --> OK\n",
      "\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o23438.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-07] 2015-07-01 00:00:00..2015-07-02 00:00:00 -> inserted: 390084\n",
      "[yellow 2015-07] 2015-07-02 00:00:00..2015-07-03 00:00:00 -> inserted: 365953\n",
      "[yellow 2015-07] 2015-07-03 00:00:00..2015-07-04 00:00:00 -> inserted: 304176\n",
      "[yellow 2015-07] 2015-07-04 00:00:00..2015-07-05 00:00:00 -> inserted: 254353\n",
      "[yellow 2015-07] 2015-07-05 00:00:00..2015-07-06 00:00:00 -> inserted: 275555\n",
      "[yellow 2015-07] 2015-07-06 00:00:00..2015-07-07 00:00:00 -> inserted: 315412\n",
      "[yellow 2015-07] 2015-07-07 00:00:00..2015-07-08 00:00:00 -> inserted: 367439\n",
      "[yellow 2015-07] 2015-07-08 00:00:00..2015-07-09 00:00:00 -> inserted: 393063\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o23639.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-07] 2015-07-09 00:00:00..2015-07-10 00:00:00 -> inserted: 405509\n",
      "[yellow 2015-07] 2015-07-10 00:00:00..2015-07-11 00:00:00 -> inserted: 400901\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o23702.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeAsyncQuery(SnowflakePreparedStatementV1.java:189)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryAsyncInterruptibly$1(SnowflakeJDBCWrapper.scala:228)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-07] 2015-07-11 00:00:00..2015-07-12 00:00:00 -> inserted: 407119\n",
      "[yellow 2015-07] 2015-07-12 00:00:00..2015-07-13 00:00:00 -> inserted: 364148\n",
      "[yellow 2015-07] 2015-07-13 00:00:00..2015-07-14 00:00:00 -> inserted: 350022\n",
      "[yellow 2015-07] 2015-07-14 00:00:00..2015-07-15 00:00:00 -> inserted: 385429\n",
      "[yellow 2015-07] 2015-07-15 00:00:00..2015-07-16 00:00:00 -> inserted: 404622\n",
      "[yellow 2015-07] 2015-07-16 00:00:00..2015-07-17 00:00:00 -> inserted: 400033\n",
      "[yellow 2015-07] 2015-07-17 00:00:00..2015-07-18 00:00:00 -> inserted: 364939\n",
      "[yellow 2015-07] 2015-07-18 00:00:00..2015-07-19 00:00:00 -> inserted: 403772\n",
      "[yellow 2015-07] 2015-07-19 00:00:00..2015-07-20 00:00:00 -> inserted: 395363\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o23926.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-07] 2015-07-20 00:00:00..2015-07-21 00:00:00 -> inserted: 374021\n",
      "[yellow 2015-07] 2015-07-21 00:00:00..2015-07-22 00:00:00 -> inserted: 374882\n",
      "[yellow 2015-07] 2015-07-22 00:00:00..2015-07-23 00:00:00 -> inserted: 391934\n",
      "[yellow 2015-07] 2015-07-23 00:00:00..2015-07-24 00:00:00 -> inserted: 403969\n",
      "[yellow 2015-07] 2015-07-24 00:00:00..2015-07-25 00:00:00 -> inserted: 403740\n",
      "[yellow 2015-07] 2015-07-25 00:00:00..2015-07-26 00:00:00 -> inserted: 386976\n",
      "[yellow 2015-07] 2015-07-26 00:00:00..2015-07-27 00:00:00 -> inserted: 349499\n",
      "[yellow 2015-07] 2015-07-27 00:00:00..2015-07-28 00:00:00 -> inserted: 348478\n",
      "[yellow 2015-07] 2015-07-28 00:00:00..2015-07-29 00:00:00 -> inserted: 384038\n",
      "[yellow 2015-07] 2015-07-29 00:00:00..2015-07-30 00:00:00 -> inserted: 405790\n",
      "[yellow 2015-07] 2015-07-30 00:00:00..2015-07-31 00:00:00 -> inserted: 390744\n",
      "[yellow 2015-07] 2015-07-31 00:00:00..2015-08-01 00:00:00 -> inserted: 397703\n",
      "\n",
      "=== RESUMEN YELLOW 2015-07 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_07\n",
      "Esperadas (parquet): 11559666\n",
      "Insertadas por loop (sin NULL): 11559666\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11559666  --> OK\n",
      "\n",
      "[yellow 2015-08] 2015-08-01 00:00:00..2015-08-02 00:00:00 -> inserted: 389634\n",
      "[yellow 2015-08] 2015-08-02 00:00:00..2015-08-03 00:00:00 -> inserted: 348443\n",
      "[yellow 2015-08] 2015-08-03 00:00:00..2015-08-04 00:00:00 -> inserted: 348518\n",
      "[yellow 2015-08] 2015-08-04 00:00:00..2015-08-05 00:00:00 -> inserted: 376230\n",
      "[yellow 2015-08] 2015-08-05 00:00:00..2015-08-06 00:00:00 -> inserted: 391340\n",
      "[yellow 2015-08] 2015-08-06 00:00:00..2015-08-07 00:00:00 -> inserted: 390661\n",
      "[yellow 2015-08] 2015-08-07 00:00:00..2015-08-08 00:00:00 -> inserted: 386638\n",
      "[yellow 2015-08] 2015-08-08 00:00:00..2015-08-09 00:00:00 -> inserted: 363330\n",
      "[yellow 2015-08] 2015-08-09 00:00:00..2015-08-10 00:00:00 -> inserted: 317502\n",
      "[yellow 2015-08] 2015-08-10 00:00:00..2015-08-11 00:00:00 -> inserted: 320736\n",
      "[yellow 2015-08] 2015-08-11 00:00:00..2015-08-12 00:00:00 -> inserted: 356926\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o24556.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-08] 2015-08-12 00:00:00..2015-08-13 00:00:00 -> inserted: 370058\n",
      "[yellow 2015-08] 2015-08-13 00:00:00..2015-08-14 00:00:00 -> inserted: 380681\n",
      "[yellow 2015-08] 2015-08-14 00:00:00..2015-08-15 00:00:00 -> inserted: 377662\n",
      "[yellow 2015-08] 2015-08-15 00:00:00..2015-08-16 00:00:00 -> inserted: 370212\n",
      "[yellow 2015-08] 2015-08-16 00:00:00..2015-08-17 00:00:00 -> inserted: 335176\n",
      "[yellow 2015-08] 2015-08-17 00:00:00..2015-08-18 00:00:00 -> inserted: 337967\n",
      "[yellow 2015-08] 2015-08-18 00:00:00..2015-08-19 00:00:00 -> inserted: 370368\n",
      "[yellow 2015-08] 2015-08-19 00:00:00..2015-08-20 00:00:00 -> inserted: 380078\n",
      "[yellow 2015-08] 2015-08-20 00:00:00..2015-08-21 00:00:00 -> inserted: 388039\n",
      "[yellow 2015-08] 2015-08-21 00:00:00..2015-08-22 00:00:00 -> inserted: 380782\n",
      "[yellow 2015-08] 2015-08-22 00:00:00..2015-08-23 00:00:00 -> inserted: 357305\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o24827.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-08] 2015-08-23 00:00:00..2015-08-24 00:00:00 -> inserted: 316148\n",
      "[yellow 2015-08] 2015-08-24 00:00:00..2015-08-25 00:00:00 -> inserted: 317316\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o24891.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-08] 2015-08-25 00:00:00..2015-08-26 00:00:00 -> inserted: 346635\n",
      "[yellow 2015-08] 2015-08-26 00:00:00..2015-08-27 00:00:00 -> inserted: 356193\n",
      "[yellow 2015-08] 2015-08-27 00:00:00..2015-08-28 00:00:00 -> inserted: 368124\n",
      "[yellow 2015-08] 2015-08-28 00:00:00..2015-08-29 00:00:00 -> inserted: 366872\n",
      "[yellow 2015-08] 2015-08-29 00:00:00..2015-08-30 00:00:00 -> inserted: 358912\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o25023.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-08] 2015-08-30 00:00:00..2015-08-31 00:00:00 -> inserted: 332473\n",
      "[yellow 2015-08] 2015-08-31 00:00:00..2015-09-01 00:00:00 -> inserted: 322164\n",
      "\n",
      "=== RESUMEN YELLOW 2015-08 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_08\n",
      "Esperadas (parquet): 11123123\n",
      "Insertadas por loop (sin NULL): 11123123\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11123123  --> OK\n",
      "\n",
      "[WARN] ensure table RAW.TRIPS_YELLOW_2015_09: An error occurred while calling o25132.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:255)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-09] 2015-09-01 00:00:00..2015-09-02 00:00:00 -> inserted: 352517\n",
      "[yellow 2015-09] 2015-09-02 00:00:00..2015-09-03 00:00:00 -> inserted: 368087\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o25219.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-09] 2015-09-03 00:00:00..2015-09-04 00:00:00 -> inserted: 377993\n",
      "[yellow 2015-09] 2015-09-04 00:00:00..2015-09-05 00:00:00 -> inserted: 361919\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o25282.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-09] 2015-09-05 00:00:00..2015-09-06 00:00:00 -> inserted: 331527\n",
      "[yellow 2015-09] 2015-09-06 00:00:00..2015-09-07 00:00:00 -> inserted: 300890\n",
      "[yellow 2015-09] 2015-09-07 00:00:00..2015-09-08 00:00:00 -> inserted: 284240\n",
      "[yellow 2015-09] 2015-09-08 00:00:00..2015-09-09 00:00:00 -> inserted: 374593\n",
      "[yellow 2015-09] 2015-09-09 00:00:00..2015-09-10 00:00:00 -> inserted: 396322\n",
      "[yellow 2015-09] 2015-09-10 00:00:00..2015-09-11 00:00:00 -> inserted: 401006\n",
      "[yellow 2015-09] 2015-09-11 00:00:00..2015-09-12 00:00:00 -> inserted: 411438\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o25461.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-09] 2015-09-12 00:00:00..2015-09-13 00:00:00 -> inserted: 433673\n",
      "[yellow 2015-09] 2015-09-13 00:00:00..2015-09-14 00:00:00 -> inserted: 382881\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o25525.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-09] 2015-09-14 00:00:00..2015-09-15 00:00:00 -> inserted: 345621\n",
      "[yellow 2015-09] 2015-09-15 00:00:00..2015-09-16 00:00:00 -> inserted: 377407\n",
      "[yellow 2015-09] 2015-09-16 00:00:00..2015-09-17 00:00:00 -> inserted: 400111\n",
      "[yellow 2015-09] 2015-09-17 00:00:00..2015-09-18 00:00:00 -> inserted: 410640\n",
      "[yellow 2015-09] 2015-09-18 00:00:00..2015-09-19 00:00:00 -> inserted: 427857\n",
      "[yellow 2015-09] 2015-09-19 00:00:00..2015-09-20 00:00:00 -> inserted: 442410\n",
      "[yellow 2015-09] 2015-09-20 00:00:00..2015-09-21 00:00:00 -> inserted: 392843\n",
      "[yellow 2015-09] 2015-09-21 00:00:00..2015-09-22 00:00:00 -> inserted: 358802\n",
      "[yellow 2015-09] 2015-09-22 00:00:00..2015-09-23 00:00:00 -> inserted: 367522\n",
      "[yellow 2015-09] 2015-09-23 00:00:00..2015-09-24 00:00:00 -> inserted: 358351\n",
      "[yellow 2015-09] 2015-09-24 00:00:00..2015-09-25 00:00:00 -> inserted: 324474\n",
      "[yellow 2015-09] 2015-09-25 00:00:00..2015-09-26 00:00:00 -> inserted: 364985\n",
      "[yellow 2015-09] 2015-09-26 00:00:00..2015-09-27 00:00:00 -> inserted: 427188\n",
      "[yellow 2015-09] 2015-09-27 00:00:00..2015-09-28 00:00:00 -> inserted: 378484\n",
      "[yellow 2015-09] 2015-09-28 00:00:00..2015-09-29 00:00:00 -> inserted: 323064\n",
      "[yellow 2015-09] 2015-09-29 00:00:00..2015-09-30 00:00:00 -> inserted: 360228\n",
      "[yellow 2015-09] 2015-09-30 00:00:00..2015-10-01 00:00:00 -> inserted: 381049\n",
      "\n",
      "=== RESUMEN YELLOW 2015-09 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_09\n",
      "Esperadas (parquet): 11218122\n",
      "Insertadas por loop (sin NULL): 11218122\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11218122  --> OK\n",
      "\n",
      "[yellow 2015-10] 2015-10-01 00:00:00..2015-10-02 00:00:00 -> inserted: 393738\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o26040.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-10] 2015-10-02 00:00:00..2015-10-03 00:00:00 -> inserted: 414055\n",
      "[yellow 2015-10] 2015-10-03 00:00:00..2015-10-04 00:00:00 -> inserted: 412561\n",
      "[yellow 2015-10] 2015-10-04 00:00:00..2015-10-05 00:00:00 -> inserted: 365074\n",
      "[yellow 2015-10] 2015-10-05 00:00:00..2015-10-06 00:00:00 -> inserted: 344478\n",
      "[yellow 2015-10] 2015-10-06 00:00:00..2015-10-07 00:00:00 -> inserted: 373924\n",
      "[yellow 2015-10] 2015-10-07 00:00:00..2015-10-08 00:00:00 -> inserted: 390684\n",
      "[yellow 2015-10] 2015-10-08 00:00:00..2015-10-09 00:00:00 -> inserted: 407269\n",
      "[yellow 2015-10] 2015-10-09 00:00:00..2015-10-10 00:00:00 -> inserted: 402390\n",
      "[yellow 2015-10] 2015-10-10 00:00:00..2015-10-11 00:00:00 -> inserted: 432480\n",
      "[yellow 2015-10] 2015-10-11 00:00:00..2015-10-12 00:00:00 -> inserted: 378149\n",
      "[yellow 2015-10] 2015-10-12 00:00:00..2015-10-13 00:00:00 -> inserted: 328111\n",
      "[yellow 2015-10] 2015-10-13 00:00:00..2015-10-14 00:00:00 -> inserted: 379081\n",
      "[yellow 2015-10] 2015-10-14 00:00:00..2015-10-15 00:00:00 -> inserted: 392444\n",
      "[yellow 2015-10] 2015-10-15 00:00:00..2015-10-16 00:00:00 -> inserted: 407178\n",
      "[yellow 2015-10] 2015-10-16 00:00:00..2015-10-17 00:00:00 -> inserted: 430097\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o26403.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-10] 2015-10-17 00:00:00..2015-10-18 00:00:00 -> inserted: 459047\n",
      "[yellow 2015-10] 2015-10-18 00:00:00..2015-10-19 00:00:00 -> inserted: 400033\n",
      "[yellow 2015-10] 2015-10-19 00:00:00..2015-10-20 00:00:00 -> inserted: 366474\n",
      "[yellow 2015-10] 2015-10-20 00:00:00..2015-10-21 00:00:00 -> inserted: 377453\n",
      "[yellow 2015-10] 2015-10-21 00:00:00..2015-10-22 00:00:00 -> inserted: 389446\n",
      "[yellow 2015-10] 2015-10-22 00:00:00..2015-10-23 00:00:00 -> inserted: 410379\n",
      "[yellow 2015-10] 2015-10-23 00:00:00..2015-10-24 00:00:00 -> inserted: 428377\n",
      "[yellow 2015-10] 2015-10-24 00:00:00..2015-10-25 00:00:00 -> inserted: 436070\n",
      "[yellow 2015-10] 2015-10-25 00:00:00..2015-10-26 00:00:00 -> inserted: 390249\n",
      "[yellow 2015-10] 2015-10-26 00:00:00..2015-10-27 00:00:00 -> inserted: 356649\n",
      "[yellow 2015-10] 2015-10-27 00:00:00..2015-10-28 00:00:00 -> inserted: 381447\n",
      "[yellow 2015-10] 2015-10-28 00:00:00..2015-10-29 00:00:00 -> inserted: 386642\n",
      "[yellow 2015-10] 2015-10-29 00:00:00..2015-10-30 00:00:00 -> inserted: 403360\n",
      "[yellow 2015-10] 2015-10-30 00:00:00..2015-10-31 00:00:00 -> inserted: 428569\n",
      "[yellow 2015-10] 2015-10-31 00:00:00..2015-11-01 00:00:00 -> inserted: 441425\n",
      "\n",
      "=== RESUMEN YELLOW 2015-10 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_10\n",
      "Esperadas (parquet): 12307333\n",
      "Insertadas por loop (sin NULL): 12307333\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 12307333  --> OK\n",
      "\n",
      "[yellow 2015-11] 2015-11-01 00:00:00..2015-11-02 00:00:00 -> inserted: 390000\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o26872.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-11] 2015-11-02 00:00:00..2015-11-03 00:00:00 -> inserted: 348229\n",
      "[yellow 2015-11] 2015-11-03 00:00:00..2015-11-04 00:00:00 -> inserted: 364749\n",
      "[yellow 2015-11] 2015-11-04 00:00:00..2015-11-05 00:00:00 -> inserted: 383808\n",
      "[yellow 2015-11] 2015-11-05 00:00:00..2015-11-06 00:00:00 -> inserted: 401912\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o26981.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-11] 2015-11-06 00:00:00..2015-11-07 00:00:00 -> inserted: 419011\n",
      "[yellow 2015-11] 2015-11-07 00:00:00..2015-11-08 00:00:00 -> inserted: 443772\n",
      "[yellow 2015-11] 2015-11-08 00:00:00..2015-11-09 00:00:00 -> inserted: 392292\n",
      "[yellow 2015-11] 2015-11-09 00:00:00..2015-11-10 00:00:00 -> inserted: 352372\n",
      "[yellow 2015-11] 2015-11-10 00:00:00..2015-11-11 00:00:00 -> inserted: 377758\n",
      "[yellow 2015-11] 2015-11-11 00:00:00..2015-11-12 00:00:00 -> inserted: 371729\n",
      "[yellow 2015-11] 2015-11-12 00:00:00..2015-11-13 00:00:00 -> inserted: 406307\n",
      "[yellow 2015-11] 2015-11-13 00:00:00..2015-11-14 00:00:00 -> inserted: 427428\n",
      "[yellow 2015-11] 2015-11-14 00:00:00..2015-11-15 00:00:00 -> inserted: 446806\n",
      "[yellow 2015-11] 2015-11-15 00:00:00..2015-11-16 00:00:00 -> inserted: 381131\n",
      "[yellow 2015-11] 2015-11-16 00:00:00..2015-11-17 00:00:00 -> inserted: 347246\n",
      "[yellow 2015-11] 2015-11-17 00:00:00..2015-11-18 00:00:00 -> inserted: 384169\n",
      "[yellow 2015-11] 2015-11-18 00:00:00..2015-11-19 00:00:00 -> inserted: 390947\n",
      "[yellow 2015-11] 2015-11-19 00:00:00..2015-11-20 00:00:00 -> inserted: 394276\n",
      "[yellow 2015-11] 2015-11-20 00:00:00..2015-11-21 00:00:00 -> inserted: 422091\n",
      "[yellow 2015-11] 2015-11-21 00:00:00..2015-11-22 00:00:00 -> inserted: 439054\n",
      "[yellow 2015-11] 2015-11-22 00:00:00..2015-11-23 00:00:00 -> inserted: 376475\n",
      "[yellow 2015-11] 2015-11-23 00:00:00..2015-11-24 00:00:00 -> inserted: 365693\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o27412.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-11] 2015-11-24 00:00:00..2015-11-25 00:00:00 -> inserted: 377626\n",
      "[yellow 2015-11] 2015-11-25 00:00:00..2015-11-26 00:00:00 -> inserted: 358414\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o27475.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-11] 2015-11-26 00:00:00..2015-11-27 00:00:00 -> inserted: 242312\n",
      "[yellow 2015-11] 2015-11-27 00:00:00..2015-11-28 00:00:00 -> inserted: 274859\n",
      "[yellow 2015-11] 2015-11-28 00:00:00..2015-11-29 00:00:00 -> inserted: 344397\n",
      "[yellow 2015-11] 2015-11-29 00:00:00..2015-11-30 00:00:00 -> inserted: 333633\n",
      "[yellow 2015-11] 2015-11-30 00:00:00..2015-12-01 00:00:00 -> inserted: 346744\n",
      "\n",
      "=== RESUMEN YELLOW 2015-11 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_11\n",
      "Esperadas (parquet): 11305240\n",
      "Insertadas por loop (sin NULL): 11305240\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11305240  --> OK\n",
      "\n",
      "[yellow 2015-12] 2015-12-01 00:00:00..2015-12-02 00:00:00 -> inserted: 374109\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o27715.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-12] 2015-12-02 00:00:00..2015-12-03 00:00:00 -> inserted: 379415\n",
      "[yellow 2015-12] 2015-12-03 00:00:00..2015-12-04 00:00:00 -> inserted: 413602\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o27778.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-12] 2015-12-04 00:00:00..2015-12-05 00:00:00 -> inserted: 430693\n",
      "[yellow 2015-12] 2015-12-05 00:00:00..2015-12-06 00:00:00 -> inserted: 450863\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o27841.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1343)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommand(SnowflakeFileTransferAgent.java:915)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.<init>(SnowflakeFileTransferAgent.java:890)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent$lzycompute(SFInternalStage.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent(SFInternalStage.scala:43)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials$lzycompute(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds$lzycompute(SFInternalStage.scala:127)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds(SFInternalStage.scala:116)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.getStageInfo(CloudStorageOperations.scala:1348)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload(CloudStorageOperations.scala:555)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload$(CloudStorageOperations.scala:550)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.upload(CloudStorageOperations.scala:1329)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: net.snowflake.client.core.SFException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null., sql state = XX000\n",
      "\tat net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:431)\n",
      "\tat net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:502)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1333)\n",
      "\t... 56 more\n",
      "\n",
      "[yellow 2015-12] 2015-12-06 00:00:00..2015-12-07 00:00:00 -> inserted: 398766\n",
      "[yellow 2015-12] 2015-12-07 00:00:00..2015-12-08 00:00:00 -> inserted: 371380\n",
      "[yellow 2015-12] 2015-12-08 00:00:00..2015-12-09 00:00:00 -> inserted: 381930\n",
      "[yellow 2015-12] 2015-12-09 00:00:00..2015-12-10 00:00:00 -> inserted: 391138\n",
      "[yellow 2015-12] 2015-12-10 00:00:00..2015-12-11 00:00:00 -> inserted: 405819\n",
      "[yellow 2015-12] 2015-12-11 00:00:00..2015-12-12 00:00:00 -> inserted: 427475\n",
      "[yellow 2015-12] 2015-12-12 00:00:00..2015-12-13 00:00:00 -> inserted: 439047\n",
      "[yellow 2015-12] 2015-12-13 00:00:00..2015-12-14 00:00:00 -> inserted: 377003\n",
      "[yellow 2015-12] 2015-12-14 00:00:00..2015-12-15 00:00:00 -> inserted: 370024\n",
      "[yellow 2015-12] 2015-12-15 00:00:00..2015-12-16 00:00:00 -> inserted: 396653\n",
      "[yellow 2015-12] 2015-12-16 00:00:00..2015-12-17 00:00:00 -> inserted: 417353\n",
      "[yellow 2015-12] 2015-12-17 00:00:00..2015-12-18 00:00:00 -> inserted: 418234\n",
      "[yellow 2015-12] 2015-12-18 00:00:00..2015-12-19 00:00:00 -> inserted: 458427\n",
      "[yellow 2015-12] 2015-12-19 00:00:00..2015-12-20 00:00:00 -> inserted: 460796\n",
      "[yellow 2015-12] 2015-12-20 00:00:00..2015-12-21 00:00:00 -> inserted: 385096\n",
      "[yellow 2015-12] 2015-12-21 00:00:00..2015-12-22 00:00:00 -> inserted: 346962\n",
      "[yellow 2015-12] 2015-12-22 00:00:00..2015-12-23 00:00:00 -> inserted: 354903\n",
      "[yellow 2015-12] 2015-12-23 00:00:00..2015-12-24 00:00:00 -> inserted: 339102\n",
      "[yellow 2015-12] 2015-12-24 00:00:00..2015-12-25 00:00:00 -> inserted: 296967\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o28296.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-12] 2015-12-25 00:00:00..2015-12-26 00:00:00 -> inserted: 188210\n",
      "[yellow 2015-12] 2015-12-26 00:00:00..2015-12-27 00:00:00 -> inserted: 238522\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o28360.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2015-12] 2015-12-27 00:00:00..2015-12-28 00:00:00 -> inserted: 268759\n",
      "[yellow 2015-12] 2015-12-28 00:00:00..2015-12-29 00:00:00 -> inserted: 301089\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o28423.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2015-12] 2015-12-29 00:00:00..2015-12-30 00:00:00 -> inserted: 311503\n",
      "[yellow 2015-12] 2015-12-30 00:00:00..2015-12-31 00:00:00 -> inserted: 319410\n",
      "[yellow 2015-12] 2015-12-31 00:00:00..2016-01-01 00:00:00 -> inserted: 339746\n",
      "\n",
      "=== RESUMEN YELLOW 2015-12 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2015_12\n",
      "Esperadas (parquet): 11452996\n",
      "Insertadas por loop (sin NULL): 11452996\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11452996  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-01.parquet\n",
      "[yellow 2016-01] 2016-01-01 00:00:00..2016-01-02 00:00:00 -> inserted: 345036\n",
      "[yellow 2016-01] 2016-01-02 00:00:00..2016-01-03 00:00:00 -> inserted: 312830\n",
      "[yellow 2016-01] 2016-01-03 00:00:00..2016-01-04 00:00:00 -> inserted: 302878\n",
      "[yellow 2016-01] 2016-01-04 00:00:00..2016-01-05 00:00:00 -> inserted: 316008\n",
      "[yellow 2016-01] 2016-01-05 00:00:00..2016-01-06 00:00:00 -> inserted: 343128\n",
      "[yellow 2016-01] 2016-01-06 00:00:00..2016-01-07 00:00:00 -> inserted: 348384\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o28732.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeAsyncQuery(SnowflakePreparedStatementV1.java:189)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryAsyncInterruptibly$1(SnowflakeJDBCWrapper.scala:228)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-01] 2016-01-07 00:00:00..2016-01-08 00:00:00 -> inserted: 364764\n",
      "[yellow 2016-01] 2016-01-08 00:00:00..2016-01-09 00:00:00 -> inserted: 391961\n",
      "[yellow 2016-01] 2016-01-09 00:00:00..2016-01-10 00:00:00 -> inserted: 405767\n",
      "[yellow 2016-01] 2016-01-10 00:00:00..2016-01-11 00:00:00 -> inserted: 351748\n",
      "[yellow 2016-01] 2016-01-11 00:00:00..2016-01-12 00:00:00 -> inserted: 342649\n",
      "[yellow 2016-01] 2016-01-12 00:00:00..2016-01-13 00:00:00 -> inserted: 367390\n",
      "[yellow 2016-01] 2016-01-13 00:00:00..2016-01-14 00:00:00 -> inserted: 395090\n",
      "[yellow 2016-01] 2016-01-14 00:00:00..2016-01-15 00:00:00 -> inserted: 396472\n",
      "[yellow 2016-01] 2016-01-15 00:00:00..2016-01-16 00:00:00 -> inserted: 401289\n",
      "[yellow 2016-01] 2016-01-16 00:00:00..2016-01-17 00:00:00 -> inserted: 411899\n",
      "[yellow 2016-01] 2016-01-17 00:00:00..2016-01-18 00:00:00 -> inserted: 379156\n",
      "[yellow 2016-01] 2016-01-18 00:00:00..2016-01-19 00:00:00 -> inserted: 341481\n",
      "[yellow 2016-01] 2016-01-19 00:00:00..2016-01-20 00:00:00 -> inserted: 385186\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o29048.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.createJDBCConnection(ServerConnection.scala:279)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.getServerConnection(ServerConnection.scala:130)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.getConnector(SnowflakeJDBCWrapper.scala:111)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:210)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-01] 2016-01-20 00:00:00..2016-01-21 00:00:00 -> inserted: 382105\n",
      "[yellow 2016-01] 2016-01-21 00:00:00..2016-01-22 00:00:00 -> inserted: 399653\n",
      "[yellow 2016-01] 2016-01-22 00:00:00..2016-01-23 00:00:00 -> inserted: 420162\n",
      "[yellow 2016-01] 2016-01-23 00:00:00..2016-01-24 00:00:00 -> inserted: 78133\n",
      "[yellow 2016-01] 2016-01-24 00:00:00..2016-01-25 00:00:00 -> inserted: 159766\n",
      "[yellow 2016-01] 2016-01-25 00:00:00..2016-01-26 00:00:00 -> inserted: 281953\n",
      "[yellow 2016-01] 2016-01-26 00:00:00..2016-01-27 00:00:00 -> inserted: 327502\n",
      "[yellow 2016-01] 2016-01-27 00:00:00..2016-01-28 00:00:00 -> inserted: 358986\n",
      "[yellow 2016-01] 2016-01-28 00:00:00..2016-01-29 00:00:00 -> inserted: 383192\n",
      "[yellow 2016-01] 2016-01-29 00:00:00..2016-01-30 00:00:00 -> inserted: 413868\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o29295.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-01] 2016-01-30 00:00:00..2016-01-31 00:00:00 -> inserted: 435231\n",
      "[yellow 2016-01] 2016-01-31 00:00:00..2016-02-01 00:00:00 -> inserted: 361400\n",
      "\n",
      "=== RESUMEN YELLOW 2016-01 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_01\n",
      "Esperadas (parquet): 10905067\n",
      "Insertadas por loop (sin NULL): 10905067\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10905067  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-02.parquet\n",
      "[yellow 2016-02] 2016-02-01 00:00:00..2016-02-02 00:00:00 -> inserted: 341035\n",
      "[yellow 2016-02] 2016-02-02 00:00:00..2016-02-03 00:00:00 -> inserted: 362900\n",
      "[yellow 2016-02] 2016-02-03 00:00:00..2016-02-04 00:00:00 -> inserted: 371808\n",
      "[yellow 2016-02] 2016-02-04 00:00:00..2016-02-05 00:00:00 -> inserted: 394475\n",
      "[yellow 2016-02] 2016-02-05 00:00:00..2016-02-06 00:00:00 -> inserted: 409211\n",
      "[yellow 2016-02] 2016-02-06 00:00:00..2016-02-07 00:00:00 -> inserted: 428301\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o29580.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-02] 2016-02-07 00:00:00..2016-02-08 00:00:00 -> inserted: 373118\n",
      "[yellow 2016-02] 2016-02-08 00:00:00..2016-02-09 00:00:00 -> inserted: 342880\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o29643.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeAsyncQuery(SnowflakePreparedStatementV1.java:189)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryAsyncInterruptibly$1(SnowflakeJDBCWrapper.scala:228)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-02] 2016-02-09 00:00:00..2016-02-10 00:00:00 -> inserted: 367712\n",
      "[yellow 2016-02] 2016-02-10 00:00:00..2016-02-11 00:00:00 -> inserted: 393112\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o29706.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1343)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommand(SnowflakeFileTransferAgent.java:915)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.<init>(SnowflakeFileTransferAgent.java:890)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent$lzycompute(SFInternalStage.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent(SFInternalStage.scala:43)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageInfo$lzycompute(SFInternalStage.scala:59)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageInfo(SFInternalStage.scala:59)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageType$lzycompute(SFInternalStage.scala:67)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageType(SFInternalStage.scala:66)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorageOperations$.createStorageClientFromStage(CloudStorageOperations.scala:239)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorageOperations$.createStorageClient(CloudStorageOperations.scala:370)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:216)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: net.snowflake.client.core.SFException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null., sql state = XX000\n",
      "\tat net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:431)\n",
      "\tat net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:502)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1333)\n",
      "\t... 54 more\n",
      "\n",
      "[yellow 2016-02] 2016-02-11 00:00:00..2016-02-12 00:00:00 -> inserted: 430922\n",
      "[yellow 2016-02] 2016-02-12 00:00:00..2016-02-13 00:00:00 -> inserted: 434042\n",
      "[yellow 2016-02] 2016-02-13 00:00:00..2016-02-14 00:00:00 -> inserted: 448500\n",
      "[yellow 2016-02] 2016-02-14 00:00:00..2016-02-15 00:00:00 -> inserted: 402370\n",
      "[yellow 2016-02] 2016-02-15 00:00:00..2016-02-16 00:00:00 -> inserted: 350101\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o29839.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1343)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommand(SnowflakeFileTransferAgent.java:915)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.<init>(SnowflakeFileTransferAgent.java:890)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent$lzycompute(SFInternalStage.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent(SFInternalStage.scala:43)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageInfo$lzycompute(SFInternalStage.scala:59)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageInfo(SFInternalStage.scala:59)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageType$lzycompute(SFInternalStage.scala:67)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.stageType(SFInternalStage.scala:66)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorageOperations$.createStorageClientFromStage(CloudStorageOperations.scala:239)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorageOperations$.createStorageClient(CloudStorageOperations.scala:370)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:216)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: net.snowflake.client.core.SFException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null., sql state = XX000\n",
      "\tat net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:431)\n",
      "\tat net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:502)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1333)\n",
      "\t... 54 more\n",
      "\n",
      "[yellow 2016-02] 2016-02-16 00:00:00..2016-02-17 00:00:00 -> inserted: 363558\n",
      "[yellow 2016-02] 2016-02-17 00:00:00..2016-02-18 00:00:00 -> inserted: 386687\n",
      "[yellow 2016-02] 2016-02-18 00:00:00..2016-02-19 00:00:00 -> inserted: 410438\n",
      "[yellow 2016-02] 2016-02-19 00:00:00..2016-02-20 00:00:00 -> inserted: 420518\n",
      "[yellow 2016-02] 2016-02-20 00:00:00..2016-02-21 00:00:00 -> inserted: 424630\n",
      "[yellow 2016-02] 2016-02-21 00:00:00..2016-02-22 00:00:00 -> inserted: 372027\n",
      "[yellow 2016-02] 2016-02-22 00:00:00..2016-02-23 00:00:00 -> inserted: 346420\n",
      "[yellow 2016-02] 2016-02-23 00:00:00..2016-02-24 00:00:00 -> inserted: 395521\n",
      "[yellow 2016-02] 2016-02-24 00:00:00..2016-02-25 00:00:00 -> inserted: 399771\n",
      "[yellow 2016-02] 2016-02-25 00:00:00..2016-02-26 00:00:00 -> inserted: 413380\n",
      "[yellow 2016-02] 2016-02-26 00:00:00..2016-02-27 00:00:00 -> inserted: 437497\n",
      "[yellow 2016-02] 2016-02-27 00:00:00..2016-02-28 00:00:00 -> inserted: 440794\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o30133.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-02] 2016-02-28 00:00:00..2016-02-29 00:00:00 -> inserted: 366136\n",
      "[yellow 2016-02] 2016-02-29 00:00:00..2016-03-01 00:00:00 -> inserted: 347548\n",
      "\n",
      "=== RESUMEN YELLOW 2016-02 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_02\n",
      "Esperadas (parquet): 11375412\n",
      "Insertadas por loop (sin NULL): 11375412\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11375412  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-03.parquet\n",
      "[yellow 2016-03] 2016-03-01 00:00:00..2016-03-02 00:00:00 -> inserted: 372582\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o30303.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-03] 2016-03-02 00:00:00..2016-03-03 00:00:00 -> inserted: 406943\n",
      "[yellow 2016-03] 2016-03-03 00:00:00..2016-03-04 00:00:00 -> inserted: 427836\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o30366.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-03] 2016-03-04 00:00:00..2016-03-05 00:00:00 -> inserted: 433873\n",
      "[yellow 2016-03] 2016-03-05 00:00:00..2016-03-06 00:00:00 -> inserted: 451068\n",
      "[yellow 2016-03] 2016-03-06 00:00:00..2016-03-07 00:00:00 -> inserted: 384985\n",
      "[yellow 2016-03] 2016-03-07 00:00:00..2016-03-08 00:00:00 -> inserted: 348362\n",
      "[yellow 2016-03] 2016-03-08 00:00:00..2016-03-09 00:00:00 -> inserted: 372636\n",
      "[yellow 2016-03] 2016-03-09 00:00:00..2016-03-10 00:00:00 -> inserted: 384276\n",
      "[yellow 2016-03] 2016-03-10 00:00:00..2016-03-11 00:00:00 -> inserted: 406323\n",
      "[yellow 2016-03] 2016-03-11 00:00:00..2016-03-12 00:00:00 -> inserted: 425022\n",
      "[yellow 2016-03] 2016-03-12 00:00:00..2016-03-13 00:00:00 -> inserted: 441937\n",
      "[yellow 2016-03] 2016-03-13 00:00:00..2016-03-14 00:00:00 -> inserted: 366741\n",
      "[yellow 2016-03] 2016-03-14 00:00:00..2016-03-15 00:00:00 -> inserted: 383635\n",
      "[yellow 2016-03] 2016-03-15 00:00:00..2016-03-16 00:00:00 -> inserted: 383015\n",
      "[yellow 2016-03] 2016-03-16 00:00:00..2016-03-17 00:00:00 -> inserted: 397851\n",
      "[yellow 2016-03] 2016-03-17 00:00:00..2016-03-18 00:00:00 -> inserted: 399438\n",
      "[yellow 2016-03] 2016-03-18 00:00:00..2016-03-19 00:00:00 -> inserted: 436509\n",
      "[yellow 2016-03] 2016-03-19 00:00:00..2016-03-20 00:00:00 -> inserted: 442036\n",
      "[yellow 2016-03] 2016-03-20 00:00:00..2016-03-21 00:00:00 -> inserted: 389552\n",
      "[yellow 2016-03] 2016-03-21 00:00:00..2016-03-22 00:00:00 -> inserted: 344081\n",
      "[yellow 2016-03] 2016-03-22 00:00:00..2016-03-23 00:00:00 -> inserted: 366497\n",
      "[yellow 2016-03] 2016-03-23 00:00:00..2016-03-24 00:00:00 -> inserted: 381525\n",
      "[yellow 2016-03] 2016-03-24 00:00:00..2016-03-25 00:00:00 -> inserted: 406739\n",
      "[yellow 2016-03] 2016-03-25 00:00:00..2016-03-26 00:00:00 -> inserted: 399500\n",
      "[yellow 2016-03] 2016-03-26 00:00:00..2016-03-27 00:00:00 -> inserted: 403777\n",
      "[yellow 2016-03] 2016-03-27 00:00:00..2016-03-28 00:00:00 -> inserted: 345466\n",
      "[yellow 2016-03] 2016-03-28 00:00:00..2016-03-29 00:00:00 -> inserted: 344392\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o30958.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-03] 2016-03-29 00:00:00..2016-03-30 00:00:00 -> inserted: 378105\n",
      "[yellow 2016-03] 2016-03-30 00:00:00..2016-03-31 00:00:00 -> inserted: 385286\n",
      "[yellow 2016-03] 2016-03-31 00:00:00..2016-04-01 00:00:00 -> inserted: 393836\n",
      "\n",
      "=== RESUMEN YELLOW 2016-03 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_03\n",
      "Esperadas (parquet): 12203824\n",
      "Insertadas por loop (sin NULL): 12203824\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 12203824  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-04.parquet\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o31128.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-04] 2016-04-01 00:00:00..2016-04-02 00:00:00 -> inserted: 411523\n",
      "[yellow 2016-04] 2016-04-02 00:00:00..2016-04-03 00:00:00 -> inserted: 444767\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o31191.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-04] 2016-04-03 00:00:00..2016-04-04 00:00:00 -> inserted: 392212\n",
      "[yellow 2016-04] 2016-04-04 00:00:00..2016-04-05 00:00:00 -> inserted: 374701\n",
      "[yellow 2016-04] 2016-04-05 00:00:00..2016-04-06 00:00:00 -> inserted: 399543\n",
      "[yellow 2016-04] 2016-04-06 00:00:00..2016-04-07 00:00:00 -> inserted: 400644\n",
      "[yellow 2016-04] 2016-04-07 00:00:00..2016-04-08 00:00:00 -> inserted: 409439\n",
      "[yellow 2016-04] 2016-04-08 00:00:00..2016-04-09 00:00:00 -> inserted: 440190\n",
      "[yellow 2016-04] 2016-04-09 00:00:00..2016-04-10 00:00:00 -> inserted: 456857\n",
      "[yellow 2016-04] 2016-04-10 00:00:00..2016-04-11 00:00:00 -> inserted: 391603\n",
      "[yellow 2016-04] 2016-04-11 00:00:00..2016-04-12 00:00:00 -> inserted: 355244\n",
      "[yellow 2016-04] 2016-04-12 00:00:00..2016-04-13 00:00:00 -> inserted: 389963\n",
      "[yellow 2016-04] 2016-04-13 00:00:00..2016-04-14 00:00:00 -> inserted: 394571\n",
      "[yellow 2016-04] 2016-04-14 00:00:00..2016-04-15 00:00:00 -> inserted: 413895\n",
      "[yellow 2016-04] 2016-04-15 00:00:00..2016-04-16 00:00:00 -> inserted: 433043\n",
      "[yellow 2016-04] 2016-04-16 00:00:00..2016-04-17 00:00:00 -> inserted: 452763\n",
      "[yellow 2016-04] 2016-04-17 00:00:00..2016-04-18 00:00:00 -> inserted: 394684\n",
      "[yellow 2016-04] 2016-04-18 00:00:00..2016-04-19 00:00:00 -> inserted: 355187\n",
      "[yellow 2016-04] 2016-04-19 00:00:00..2016-04-20 00:00:00 -> inserted: 377505\n",
      "[yellow 2016-04] 2016-04-20 00:00:00..2016-04-21 00:00:00 -> inserted: 395339\n",
      "[yellow 2016-04] 2016-04-21 00:00:00..2016-04-22 00:00:00 -> inserted: 390144\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o31645.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-04] 2016-04-22 00:00:00..2016-04-23 00:00:00 -> inserted: 388149\n",
      "[yellow 2016-04] 2016-04-23 00:00:00..2016-04-24 00:00:00 -> inserted: 391672\n",
      "[yellow 2016-04] 2016-04-24 00:00:00..2016-04-25 00:00:00 -> inserted: 357425\n",
      "[yellow 2016-04] 2016-04-25 00:00:00..2016-04-26 00:00:00 -> inserted: 332897\n",
      "[yellow 2016-04] 2016-04-26 00:00:00..2016-04-27 00:00:00 -> inserted: 371140\n",
      "[yellow 2016-04] 2016-04-27 00:00:00..2016-04-28 00:00:00 -> inserted: 374743\n",
      "[yellow 2016-04] 2016-04-28 00:00:00..2016-04-29 00:00:00 -> inserted: 401437\n",
      "[yellow 2016-04] 2016-04-29 00:00:00..2016-04-30 00:00:00 -> inserted: 416299\n",
      "[yellow 2016-04] 2016-04-30 00:00:00..2016-05-01 00:00:00 -> inserted: 420417\n",
      "\n",
      "=== RESUMEN YELLOW 2016-04 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_04\n",
      "Esperadas (parquet): 11927996\n",
      "Insertadas por loop (sin NULL): 11927996\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11927996  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-05.parquet\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o31953.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-05] 2016-05-01 00:00:00..2016-05-02 00:00:00 -> inserted: 382033\n",
      "[yellow 2016-05] 2016-05-02 00:00:00..2016-05-03 00:00:00 -> inserted: 357271\n",
      "[yellow 2016-05] 2016-05-03 00:00:00..2016-05-04 00:00:00 -> inserted: 400206\n",
      "[yellow 2016-05] 2016-05-04 00:00:00..2016-05-05 00:00:00 -> inserted: 407024\n",
      "[yellow 2016-05] 2016-05-05 00:00:00..2016-05-06 00:00:00 -> inserted: 424108\n",
      "[yellow 2016-05] 2016-05-06 00:00:00..2016-05-07 00:00:00 -> inserted: 436846\n",
      "[yellow 2016-05] 2016-05-07 00:00:00..2016-05-08 00:00:00 -> inserted: 433170\n",
      "[yellow 2016-05] 2016-05-08 00:00:00..2016-05-09 00:00:00 -> inserted: 373216\n",
      "[yellow 2016-05] 2016-05-09 00:00:00..2016-05-10 00:00:00 -> inserted: 348913\n",
      "[yellow 2016-05] 2016-05-10 00:00:00..2016-05-11 00:00:00 -> inserted: 376087\n",
      "[yellow 2016-05] 2016-05-11 00:00:00..2016-05-12 00:00:00 -> inserted: 383331\n",
      "[yellow 2016-05] 2016-05-12 00:00:00..2016-05-13 00:00:00 -> inserted: 399990\n",
      "[yellow 2016-05] 2016-05-13 00:00:00..2016-05-14 00:00:00 -> inserted: 396978\n",
      "[yellow 2016-05] 2016-05-14 00:00:00..2016-05-15 00:00:00 -> inserted: 435365\n",
      "[yellow 2016-05] 2016-05-15 00:00:00..2016-05-16 00:00:00 -> inserted: 408406\n",
      "[yellow 2016-05] 2016-05-16 00:00:00..2016-05-17 00:00:00 -> inserted: 378620\n",
      "[yellow 2016-05] 2016-05-17 00:00:00..2016-05-18 00:00:00 -> inserted: 397492\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o32361.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-05] 2016-05-18 00:00:00..2016-05-19 00:00:00 -> inserted: 381183\n",
      "[yellow 2016-05] 2016-05-19 00:00:00..2016-05-20 00:00:00 -> inserted: 405850\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o32424.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeAsyncQuery(SnowflakePreparedStatementV1.java:189)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryAsyncInterruptibly$1(SnowflakeJDBCWrapper.scala:228)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-05] 2016-05-20 00:00:00..2016-05-21 00:00:00 -> inserted: 414540\n",
      "[yellow 2016-05] 2016-05-21 00:00:00..2016-05-22 00:00:00 -> inserted: 435779\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o32487.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1343)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommand(SnowflakeFileTransferAgent.java:915)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.<init>(SnowflakeFileTransferAgent.java:890)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent$lzycompute(SFInternalStage.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent(SFInternalStage.scala:43)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials$lzycompute(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds$lzycompute(SFInternalStage.scala:127)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds(SFInternalStage.scala:116)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.getStageInfo(CloudStorageOperations.scala:1348)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload(CloudStorageOperations.scala:555)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload$(CloudStorageOperations.scala:550)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.upload(CloudStorageOperations.scala:1329)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: net.snowflake.client.core.SFException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null., sql state = XX000\n",
      "\tat net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:431)\n",
      "\tat net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:502)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1333)\n",
      "\t... 56 more\n",
      "\n",
      "[yellow 2016-05] 2016-05-22 00:00:00..2016-05-23 00:00:00 -> inserted: 369293\n",
      "[yellow 2016-05] 2016-05-23 00:00:00..2016-05-24 00:00:00 -> inserted: 346799\n",
      "[yellow 2016-05] 2016-05-24 00:00:00..2016-05-25 00:00:00 -> inserted: 371272\n",
      "[yellow 2016-05] 2016-05-25 00:00:00..2016-05-26 00:00:00 -> inserted: 385701\n",
      "[yellow 2016-05] 2016-05-26 00:00:00..2016-05-27 00:00:00 -> inserted: 388432\n",
      "[yellow 2016-05] 2016-05-27 00:00:00..2016-05-28 00:00:00 -> inserted: 364741\n",
      "[yellow 2016-05] 2016-05-28 00:00:00..2016-05-29 00:00:00 -> inserted: 329663\n",
      "[yellow 2016-05] 2016-05-29 00:00:00..2016-05-30 00:00:00 -> inserted: 298102\n",
      "[yellow 2016-05] 2016-05-30 00:00:00..2016-05-31 00:00:00 -> inserted: 261093\n",
      "[yellow 2016-05] 2016-05-31 00:00:00..2016-06-01 00:00:00 -> inserted: 340545\n",
      "\n",
      "=== RESUMEN YELLOW 2016-05 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_05\n",
      "Esperadas (parquet): 11832049\n",
      "Insertadas por loop (sin NULL): 11832049\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11832049  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-06.parquet\n",
      "[yellow 2016-06] 2016-06-01 00:00:00..2016-06-02 00:00:00 -> inserted: 368507\n",
      "[yellow 2016-06] 2016-06-02 00:00:00..2016-06-03 00:00:00 -> inserted: 392689\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o32865.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-06] 2016-06-03 00:00:00..2016-06-04 00:00:00 -> inserted: 401623\n",
      "[yellow 2016-06] 2016-06-04 00:00:00..2016-06-05 00:00:00 -> inserted: 420418\n",
      "[yellow 2016-06] 2016-06-05 00:00:00..2016-06-06 00:00:00 -> inserted: 353060\n",
      "[yellow 2016-06] 2016-06-06 00:00:00..2016-06-07 00:00:00 -> inserted: 356341\n",
      "[yellow 2016-06] 2016-06-07 00:00:00..2016-06-08 00:00:00 -> inserted: 376176\n",
      "[yellow 2016-06] 2016-06-08 00:00:00..2016-06-09 00:00:00 -> inserted: 381327\n",
      "[yellow 2016-06] 2016-06-09 00:00:00..2016-06-10 00:00:00 -> inserted: 393423\n",
      "[yellow 2016-06] 2016-06-10 00:00:00..2016-06-11 00:00:00 -> inserted: 401213\n",
      "[yellow 2016-06] 2016-06-11 00:00:00..2016-06-12 00:00:00 -> inserted: 387859\n",
      "[yellow 2016-06] 2016-06-12 00:00:00..2016-06-13 00:00:00 -> inserted: 329071\n",
      "[yellow 2016-06] 2016-06-13 00:00:00..2016-06-14 00:00:00 -> inserted: 340840\n",
      "[yellow 2016-06] 2016-06-14 00:00:00..2016-06-15 00:00:00 -> inserted: 363176\n",
      "[yellow 2016-06] 2016-06-15 00:00:00..2016-06-16 00:00:00 -> inserted: 382925\n",
      "[yellow 2016-06] 2016-06-16 00:00:00..2016-06-17 00:00:00 -> inserted: 398570\n",
      "[yellow 2016-06] 2016-06-17 00:00:00..2016-06-18 00:00:00 -> inserted: 388251\n",
      "[yellow 2016-06] 2016-06-18 00:00:00..2016-06-19 00:00:00 -> inserted: 370615\n",
      "[yellow 2016-06] 2016-06-19 00:00:00..2016-06-20 00:00:00 -> inserted: 330252\n",
      "[yellow 2016-06] 2016-06-20 00:00:00..2016-06-21 00:00:00 -> inserted: 335804\n",
      "[yellow 2016-06] 2016-06-21 00:00:00..2016-06-22 00:00:00 -> inserted: 364408\n",
      "[yellow 2016-06] 2016-06-22 00:00:00..2016-06-23 00:00:00 -> inserted: 373321\n",
      "[yellow 2016-06] 2016-06-23 00:00:00..2016-06-24 00:00:00 -> inserted: 389995\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o33365.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-06] 2016-06-24 00:00:00..2016-06-25 00:00:00 -> inserted: 388386\n",
      "[yellow 2016-06] 2016-06-25 00:00:00..2016-06-26 00:00:00 -> inserted: 388909\n",
      "[yellow 2016-06] 2016-06-26 00:00:00..2016-06-27 00:00:00 -> inserted: 331894\n",
      "[yellow 2016-06] 2016-06-27 00:00:00..2016-06-28 00:00:00 -> inserted: 358631\n",
      "[yellow 2016-06] 2016-06-28 00:00:00..2016-06-29 00:00:00 -> inserted: 348616\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o33497.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1343)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommand(SnowflakeFileTransferAgent.java:915)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.<init>(SnowflakeFileTransferAgent.java:890)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent$lzycompute(SFInternalStage.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.sfAgent(SFInternalStage.scala:43)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials$lzycompute(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.encryptionMaterials(SFInternalStage.scala:54)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds$lzycompute(SFInternalStage.scala:127)\n",
      "\tat net.snowflake.spark.snowflake.io.SFInternalStage.getKeyIds(SFInternalStage.scala:116)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.getStageInfo(CloudStorageOperations.scala:1348)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload(CloudStorageOperations.scala:555)\n",
      "\tat net.snowflake.spark.snowflake.io.CloudStorage.upload$(CloudStorageOperations.scala:550)\n",
      "\tat net.snowflake.spark.snowflake.io.InternalS3Storage.upload(CloudStorageOperations.scala:1329)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: net.snowflake.client.core.SFException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null., sql state = XX000\n",
      "\tat net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:431)\n",
      "\tat net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:502)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeFileTransferAgent.parseCommandInGS(SnowflakeFileTransferAgent.java:1333)\n",
      "\t... 56 more\n",
      "\n",
      "[yellow 2016-06] 2016-06-29 00:00:00..2016-06-30 00:00:00 -> inserted: 357123\n",
      "[yellow 2016-06] 2016-06-30 00:00:00..2016-07-01 00:00:00 -> inserted: 358222\n",
      "\n",
      "=== RESUMEN YELLOW 2016-06 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_06\n",
      "Esperadas (parquet): 11131645\n",
      "Insertadas por loop (sin NULL): 11131645\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 11131645  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-07.parquet\n",
      "[yellow 2016-07] 2016-07-01 00:00:00..2016-07-02 00:00:00 -> inserted: 324990\n",
      "[yellow 2016-07] 2016-07-02 00:00:00..2016-07-03 00:00:00 -> inserted: 266276\n",
      "[yellow 2016-07] 2016-07-03 00:00:00..2016-07-04 00:00:00 -> inserted: 232343\n",
      "[yellow 2016-07] 2016-07-04 00:00:00..2016-07-05 00:00:00 -> inserted: 226837\n",
      "[yellow 2016-07] 2016-07-05 00:00:00..2016-07-06 00:00:00 -> inserted: 293436\n",
      "[yellow 2016-07] 2016-07-06 00:00:00..2016-07-07 00:00:00 -> inserted: 311148\n",
      "[yellow 2016-07] 2016-07-07 00:00:00..2016-07-08 00:00:00 -> inserted: 350404\n",
      "[yellow 2016-07] 2016-07-08 00:00:00..2016-07-09 00:00:00 -> inserted: 347552\n",
      "[yellow 2016-07] 2016-07-09 00:00:00..2016-07-10 00:00:00 -> inserted: 333013\n",
      "[yellow 2016-07] 2016-07-10 00:00:00..2016-07-11 00:00:00 -> inserted: 302693\n",
      "[yellow 2016-07] 2016-07-11 00:00:00..2016-07-12 00:00:00 -> inserted: 306637\n",
      "[yellow 2016-07] 2016-07-12 00:00:00..2016-07-13 00:00:00 -> inserted: 341393\n",
      "[yellow 2016-07] 2016-07-13 00:00:00..2016-07-14 00:00:00 -> inserted: 370677\n",
      "[yellow 2016-07] 2016-07-14 00:00:00..2016-07-15 00:00:00 -> inserted: 374150\n",
      "[yellow 2016-07] 2016-07-15 00:00:00..2016-07-16 00:00:00 -> inserted: 373908\n",
      "[yellow 2016-07] 2016-07-16 00:00:00..2016-07-17 00:00:00 -> inserted: 350449\n",
      "[yellow 2016-07] 2016-07-17 00:00:00..2016-07-18 00:00:00 -> inserted: 325670\n",
      "[yellow 2016-07] 2016-07-18 00:00:00..2016-07-19 00:00:00 -> inserted: 329661\n",
      "[yellow 2016-07] 2016-07-19 00:00:00..2016-07-20 00:00:00 -> inserted: 344310\n",
      "[yellow 2016-07] 2016-07-20 00:00:00..2016-07-21 00:00:00 -> inserted: 357482\n",
      "[yellow 2016-07] 2016-07-21 00:00:00..2016-07-22 00:00:00 -> inserted: 363728\n",
      "[yellow 2016-07] 2016-07-22 00:00:00..2016-07-23 00:00:00 -> inserted: 375854\n",
      "[yellow 2016-07] 2016-07-23 00:00:00..2016-07-24 00:00:00 -> inserted: 355724\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o34174.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-07] 2016-07-24 00:00:00..2016-07-25 00:00:00 -> inserted: 322468\n",
      "[yellow 2016-07] 2016-07-25 00:00:00..2016-07-26 00:00:00 -> inserted: 320976\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o34237.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-07] 2016-07-26 00:00:00..2016-07-27 00:00:00 -> inserted: 350450\n",
      "[yellow 2016-07] 2016-07-27 00:00:00..2016-07-28 00:00:00 -> inserted: 362177\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o34301.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-07] 2016-07-28 00:00:00..2016-07-29 00:00:00 -> inserted: 369819\n",
      "[yellow 2016-07] 2016-07-29 00:00:00..2016-07-30 00:00:00 -> inserted: 360758\n",
      "[yellow 2016-07] 2016-07-30 00:00:00..2016-07-31 00:00:00 -> inserted: 343574\n",
      "[yellow 2016-07] 2016-07-31 00:00:00..2016-08-01 00:00:00 -> inserted: 305523\n",
      "\n",
      "=== RESUMEN YELLOW 2016-07 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_07\n",
      "Esperadas (parquet): 10294080\n",
      "Insertadas por loop (sin NULL): 10294080\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10294080  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-08.parquet\n",
      "[yellow 2016-08] 2016-08-01 00:00:00..2016-08-02 00:00:00 -> inserted: 308763\n",
      "[yellow 2016-08] 2016-08-02 00:00:00..2016-08-03 00:00:00 -> inserted: 330690\n",
      "[yellow 2016-08] 2016-08-03 00:00:00..2016-08-04 00:00:00 -> inserted: 339751\n",
      "[yellow 2016-08] 2016-08-04 00:00:00..2016-08-05 00:00:00 -> inserted: 353411\n",
      "[yellow 2016-08] 2016-08-05 00:00:00..2016-08-06 00:00:00 -> inserted: 343476\n",
      "[yellow 2016-08] 2016-08-06 00:00:00..2016-08-07 00:00:00 -> inserted: 324402\n",
      "[yellow 2016-08] 2016-08-07 00:00:00..2016-08-08 00:00:00 -> inserted: 291897\n",
      "[yellow 2016-08] 2016-08-08 00:00:00..2016-08-09 00:00:00 -> inserted: 291540\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o34678.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-08] 2016-08-09 00:00:00..2016-08-10 00:00:00 -> inserted: 327187\n",
      "[yellow 2016-08] 2016-08-10 00:00:00..2016-08-11 00:00:00 -> inserted: 345235\n",
      "[yellow 2016-08] 2016-08-11 00:00:00..2016-08-12 00:00:00 -> inserted: 364860\n",
      "[yellow 2016-08] 2016-08-12 00:00:00..2016-08-13 00:00:00 -> inserted: 359868\n",
      "[yellow 2016-08] 2016-08-13 00:00:00..2016-08-14 00:00:00 -> inserted: 338325\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o34810.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-08] 2016-08-14 00:00:00..2016-08-15 00:00:00 -> inserted: 287668\n",
      "[yellow 2016-08] 2016-08-15 00:00:00..2016-08-16 00:00:00 -> inserted: 306100\n",
      "[yellow 2016-08] 2016-08-16 00:00:00..2016-08-17 00:00:00 -> inserted: 333615\n",
      "[yellow 2016-08] 2016-08-17 00:00:00..2016-08-18 00:00:00 -> inserted: 335237\n",
      "[yellow 2016-08] 2016-08-18 00:00:00..2016-08-19 00:00:00 -> inserted: 343959\n",
      "[yellow 2016-08] 2016-08-19 00:00:00..2016-08-20 00:00:00 -> inserted: 338709\n",
      "[yellow 2016-08] 2016-08-20 00:00:00..2016-08-21 00:00:00 -> inserted: 314436\n",
      "[yellow 2016-08] 2016-08-21 00:00:00..2016-08-22 00:00:00 -> inserted: 290441\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o35012.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-08] 2016-08-22 00:00:00..2016-08-23 00:00:00 -> inserted: 283148\n",
      "[yellow 2016-08] 2016-08-23 00:00:00..2016-08-24 00:00:00 -> inserted: 305068\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o35076.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-08] 2016-08-24 00:00:00..2016-08-25 00:00:00 -> inserted: 321490\n",
      "[yellow 2016-08] 2016-08-25 00:00:00..2016-08-26 00:00:00 -> inserted: 332810\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o35140.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-08] 2016-08-26 00:00:00..2016-08-27 00:00:00 -> inserted: 325712\n",
      "[yellow 2016-08] 2016-08-27 00:00:00..2016-08-28 00:00:00 -> inserted: 309307\n",
      "[yellow 2016-08] 2016-08-28 00:00:00..2016-08-29 00:00:00 -> inserted: 286052\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o35226.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-08] 2016-08-29 00:00:00..2016-08-30 00:00:00 -> inserted: 287726\n",
      "[yellow 2016-08] 2016-08-30 00:00:00..2016-08-31 00:00:00 -> inserted: 300429\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o35289.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-08] 2016-08-31 00:00:00..2016-09-01 00:00:00 -> inserted: 320951\n",
      "\n",
      "=== RESUMEN YELLOW 2016-08 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_08\n",
      "Esperadas (parquet): 9942263\n",
      "Insertadas por loop (sin NULL): 9942263\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 9942263  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-09.parquet\n",
      "[yellow 2016-09] 2016-09-01 00:00:00..2016-09-02 00:00:00 -> inserted: 328731\n",
      "[yellow 2016-09] 2016-09-02 00:00:00..2016-09-03 00:00:00 -> inserted: 302022\n",
      "[yellow 2016-09] 2016-09-03 00:00:00..2016-09-04 00:00:00 -> inserted: 270399\n",
      "[yellow 2016-09] 2016-09-04 00:00:00..2016-09-05 00:00:00 -> inserted: 246690\n",
      "[yellow 2016-09] 2016-09-05 00:00:00..2016-09-06 00:00:00 -> inserted: 234286\n",
      "[yellow 2016-09] 2016-09-06 00:00:00..2016-09-07 00:00:00 -> inserted: 320607\n",
      "[yellow 2016-09] 2016-09-07 00:00:00..2016-09-08 00:00:00 -> inserted: 352110\n",
      "[yellow 2016-09] 2016-09-08 00:00:00..2016-09-09 00:00:00 -> inserted: 374100\n",
      "[yellow 2016-09] 2016-09-09 00:00:00..2016-09-10 00:00:00 -> inserted: 383524\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o35620.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-09] 2016-09-10 00:00:00..2016-09-11 00:00:00 -> inserted: 391609\n",
      "[yellow 2016-09] 2016-09-11 00:00:00..2016-09-12 00:00:00 -> inserted: 339972\n",
      "[yellow 2016-09] 2016-09-12 00:00:00..2016-09-13 00:00:00 -> inserted: 306087\n",
      "[yellow 2016-09] 2016-09-13 00:00:00..2016-09-14 00:00:00 -> inserted: 342943\n",
      "[yellow 2016-09] 2016-09-14 00:00:00..2016-09-15 00:00:00 -> inserted: 354721\n",
      "[yellow 2016-09] 2016-09-15 00:00:00..2016-09-16 00:00:00 -> inserted: 365148\n",
      "[yellow 2016-09] 2016-09-16 00:00:00..2016-09-17 00:00:00 -> inserted: 371738\n",
      "[yellow 2016-09] 2016-09-17 00:00:00..2016-09-18 00:00:00 -> inserted: 375619\n",
      "[yellow 2016-09] 2016-09-18 00:00:00..2016-09-19 00:00:00 -> inserted: 332291\n",
      "[yellow 2016-09] 2016-09-19 00:00:00..2016-09-20 00:00:00 -> inserted: 293917\n",
      "[yellow 2016-09] 2016-09-20 00:00:00..2016-09-21 00:00:00 -> inserted: 315049\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o35890.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-09] 2016-09-21 00:00:00..2016-09-22 00:00:00 -> inserted: 325578\n",
      "[yellow 2016-09] 2016-09-22 00:00:00..2016-09-23 00:00:00 -> inserted: 349716\n",
      "[yellow 2016-09] 2016-09-23 00:00:00..2016-09-24 00:00:00 -> inserted: 359645\n",
      "[yellow 2016-09] 2016-09-24 00:00:00..2016-09-25 00:00:00 -> inserted: 378181\n",
      "[yellow 2016-09] 2016-09-25 00:00:00..2016-09-26 00:00:00 -> inserted: 337791\n",
      "[yellow 2016-09] 2016-09-26 00:00:00..2016-09-27 00:00:00 -> inserted: 320999\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o36045.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-09] 2016-09-27 00:00:00..2016-09-28 00:00:00 -> inserted: 342012\n",
      "[yellow 2016-09] 2016-09-28 00:00:00..2016-09-29 00:00:00 -> inserted: 360689\n",
      "[yellow 2016-09] 2016-09-29 00:00:00..2016-09-30 00:00:00 -> inserted: 367890\n",
      "[yellow 2016-09] 2016-09-30 00:00:00..2016-10-01 00:00:00 -> inserted: 371954\n",
      "\n",
      "=== RESUMEN YELLOW 2016-09 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_09\n",
      "Esperadas (parquet): 10116018\n",
      "Insertadas por loop (sin NULL): 10116018\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10116018  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-10.parquet\n",
      "[WARN] truncate RAW.TRIPS_YELLOW_2016_10: An error occurred while calling o36216.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.createJDBCConnection(ServerConnection.scala:279)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection$.getServerConnection(ServerConnection.scala:130)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.getConnector(SnowflakeJDBCWrapper.scala:111)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:210)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-10] 2016-10-01 00:00:00..2016-10-02 00:00:00 -> inserted: 368086\n",
      "[yellow 2016-10] 2016-10-02 00:00:00..2016-10-03 00:00:00 -> inserted: 324835\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o36286.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-10] 2016-10-03 00:00:00..2016-10-04 00:00:00 -> inserted: 288557\n",
      "[yellow 2016-10] 2016-10-04 00:00:00..2016-10-05 00:00:00 -> inserted: 319555\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o36350.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-10] 2016-10-05 00:00:00..2016-10-06 00:00:00 -> inserted: 358090\n",
      "[yellow 2016-10] 2016-10-06 00:00:00..2016-10-07 00:00:00 -> inserted: 370539\n",
      "[yellow 2016-10] 2016-10-07 00:00:00..2016-10-08 00:00:00 -> inserted: 366376\n",
      "[yellow 2016-10] 2016-10-08 00:00:00..2016-10-09 00:00:00 -> inserted: 378088\n",
      "[yellow 2016-10] 2016-10-09 00:00:00..2016-10-10 00:00:00 -> inserted: 333626\n",
      "[yellow 2016-10] 2016-10-10 00:00:00..2016-10-11 00:00:00 -> inserted: 291791\n",
      "[yellow 2016-10] 2016-10-11 00:00:00..2016-10-12 00:00:00 -> inserted: 321694\n",
      "[yellow 2016-10] 2016-10-12 00:00:00..2016-10-13 00:00:00 -> inserted: 320177\n",
      "[yellow 2016-10] 2016-10-13 00:00:00..2016-10-14 00:00:00 -> inserted: 367959\n",
      "[yellow 2016-10] 2016-10-14 00:00:00..2016-10-15 00:00:00 -> inserted: 380513\n",
      "[yellow 2016-10] 2016-10-15 00:00:00..2016-10-16 00:00:00 -> inserted: 381537\n",
      "[yellow 2016-10] 2016-10-16 00:00:00..2016-10-17 00:00:00 -> inserted: 335589\n",
      "[yellow 2016-10] 2016-10-17 00:00:00..2016-10-18 00:00:00 -> inserted: 315861\n",
      "[yellow 2016-10] 2016-10-18 00:00:00..2016-10-19 00:00:00 -> inserted: 339332\n",
      "[yellow 2016-10] 2016-10-19 00:00:00..2016-10-20 00:00:00 -> inserted: 355020\n",
      "[yellow 2016-10] 2016-10-20 00:00:00..2016-10-21 00:00:00 -> inserted: 366184\n",
      "[yellow 2016-10] 2016-10-21 00:00:00..2016-10-22 00:00:00 -> inserted: 376369\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o36758.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-10] 2016-10-22 00:00:00..2016-10-23 00:00:00 -> inserted: 401855\n",
      "[yellow 2016-10] 2016-10-23 00:00:00..2016-10-24 00:00:00 -> inserted: 343516\n",
      "[yellow 2016-10] 2016-10-24 00:00:00..2016-10-25 00:00:00 -> inserted: 326669\n",
      "[yellow 2016-10] 2016-10-25 00:00:00..2016-10-26 00:00:00 -> inserted: 359918\n",
      "[yellow 2016-10] 2016-10-26 00:00:00..2016-10-27 00:00:00 -> inserted: 366660\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o36891.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-10] 2016-10-27 00:00:00..2016-10-28 00:00:00 -> inserted: 363272\n",
      "[yellow 2016-10] 2016-10-28 00:00:00..2016-10-29 00:00:00 -> inserted: 387361\n",
      "[yellow 2016-10] 2016-10-29 00:00:00..2016-10-30 00:00:00 -> inserted: 390484\n",
      "[yellow 2016-10] 2016-10-30 00:00:00..2016-10-31 00:00:00 -> inserted: 344633\n",
      "[yellow 2016-10] 2016-10-31 00:00:00..2016-11-01 00:00:00 -> inserted: 310480\n",
      "[WARN] count intento 1/5 falló: An error occurred while calling o37018.collectToPython.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "\n",
      "=== RESUMEN YELLOW 2016-10 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_10\n",
      "Esperadas (parquet): 10854626\n",
      "Insertadas por loop (sin NULL): 10854626\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10854626  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-11.parquet\n",
      "[yellow 2016-11] 2016-11-01 00:00:00..2016-11-02 00:00:00 -> inserted: 355424\n",
      "[yellow 2016-11] 2016-11-02 00:00:00..2016-11-03 00:00:00 -> inserted: 346670\n",
      "[yellow 2016-11] 2016-11-03 00:00:00..2016-11-04 00:00:00 -> inserted: 373793\n",
      "[yellow 2016-11] 2016-11-04 00:00:00..2016-11-05 00:00:00 -> inserted: 378670\n",
      "[yellow 2016-11] 2016-11-05 00:00:00..2016-11-06 00:00:00 -> inserted: 392295\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o37237.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQuery(SnowflakeStatementV1.java:149)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:188)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-11] 2016-11-06 00:00:00..2016-11-07 00:00:00 -> inserted: 336730\n",
      "[yellow 2016-11] 2016-11-07 00:00:00..2016-11-08 00:00:00 -> inserted: 322666\n",
      "[yellow 2016-11] 2016-11-08 00:00:00..2016-11-09 00:00:00 -> inserted: 318981\n",
      "[yellow 2016-11] 2016-11-09 00:00:00..2016-11-10 00:00:00 -> inserted: 355018\n",
      "[yellow 2016-11] 2016-11-10 00:00:00..2016-11-11 00:00:00 -> inserted: 359630\n",
      "[yellow 2016-11] 2016-11-11 00:00:00..2016-11-12 00:00:00 -> inserted: 365267\n",
      "[yellow 2016-11] 2016-11-12 00:00:00..2016-11-13 00:00:00 -> inserted: 382598\n",
      "[yellow 2016-11] 2016-11-13 00:00:00..2016-11-14 00:00:00 -> inserted: 339631\n",
      "[yellow 2016-11] 2016-11-14 00:00:00..2016-11-15 00:00:00 -> inserted: 319067\n",
      "[yellow 2016-11] 2016-11-15 00:00:00..2016-11-16 00:00:00 -> inserted: 349883\n",
      "[yellow 2016-11] 2016-11-16 00:00:00..2016-11-17 00:00:00 -> inserted: 348325\n",
      "[yellow 2016-11] 2016-11-17 00:00:00..2016-11-18 00:00:00 -> inserted: 359986\n",
      "[yellow 2016-11] 2016-11-18 00:00:00..2016-11-19 00:00:00 -> inserted: 372328\n",
      "[yellow 2016-11] 2016-11-19 00:00:00..2016-11-20 00:00:00 -> inserted: 384371\n",
      "[yellow 2016-11] 2016-11-20 00:00:00..2016-11-21 00:00:00 -> inserted: 337966\n",
      "[yellow 2016-11] 2016-11-21 00:00:00..2016-11-22 00:00:00 -> inserted: 328811\n",
      "[yellow 2016-11] 2016-11-22 00:00:00..2016-11-23 00:00:00 -> inserted: 345462\n",
      "[yellow 2016-11] 2016-11-23 00:00:00..2016-11-24 00:00:00 -> inserted: 325062\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o37668.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-11] 2016-11-24 00:00:00..2016-11-25 00:00:00 -> inserted: 219830\n",
      "[yellow 2016-11] 2016-11-25 00:00:00..2016-11-26 00:00:00 -> inserted: 244016\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o37732.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2016-11] 2016-11-26 00:00:00..2016-11-27 00:00:00 -> inserted: 297411\n",
      "[yellow 2016-11] 2016-11-27 00:00:00..2016-11-28 00:00:00 -> inserted: 282571\n",
      "[yellow 2016-11] 2016-11-28 00:00:00..2016-11-29 00:00:00 -> inserted: 298385\n",
      "[yellow 2016-11] 2016-11-29 00:00:00..2016-11-30 00:00:00 -> inserted: 323949\n",
      "[yellow 2016-11] 2016-11-30 00:00:00..2016-12-01 00:00:00 -> inserted: 337332\n",
      "\n",
      "=== RESUMEN YELLOW 2016-11 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_11\n",
      "Esperadas (parquet): 10102128\n",
      "Insertadas por loop (sin NULL): 10102128\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10102128  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-12.parquet\n",
      "[yellow 2016-12] 2016-12-01 00:00:00..2016-12-02 00:00:00 -> inserted: 364949\n",
      "[yellow 2016-12] 2016-12-02 00:00:00..2016-12-03 00:00:00 -> inserted: 390235\n",
      "[yellow 2016-12] 2016-12-03 00:00:00..2016-12-04 00:00:00 -> inserted: 400785\n",
      "[yellow 2016-12] 2016-12-04 00:00:00..2016-12-05 00:00:00 -> inserted: 346550\n",
      "[yellow 2016-12] 2016-12-05 00:00:00..2016-12-06 00:00:00 -> inserted: 333589\n",
      "[yellow 2016-12] 2016-12-06 00:00:00..2016-12-07 00:00:00 -> inserted: 350832\n",
      "[yellow 2016-12] 2016-12-07 00:00:00..2016-12-08 00:00:00 -> inserted: 361705\n",
      "[yellow 2016-12] 2016-12-08 00:00:00..2016-12-09 00:00:00 -> inserted: 377374\n",
      "[yellow 2016-12] 2016-12-09 00:00:00..2016-12-10 00:00:00 -> inserted: 405547\n",
      "[yellow 2016-12] 2016-12-10 00:00:00..2016-12-11 00:00:00 -> inserted: 412173\n",
      "[yellow 2016-12] 2016-12-11 00:00:00..2016-12-12 00:00:00 -> inserted: 341580\n",
      "[yellow 2016-12] 2016-12-12 00:00:00..2016-12-13 00:00:00 -> inserted: 330218\n",
      "[yellow 2016-12] 2016-12-13 00:00:00..2016-12-14 00:00:00 -> inserted: 352855\n",
      "[yellow 2016-12] 2016-12-14 00:00:00..2016-12-15 00:00:00 -> inserted: 375027\n",
      "[yellow 2016-12] 2016-12-15 00:00:00..2016-12-16 00:00:00 -> inserted: 404341\n",
      "[yellow 2016-12] 2016-12-16 00:00:00..2016-12-17 00:00:00 -> inserted: 419164\n",
      "[yellow 2016-12] 2016-12-17 00:00:00..2016-12-18 00:00:00 -> inserted: 390324\n",
      "[yellow 2016-12] 2016-12-18 00:00:00..2016-12-19 00:00:00 -> inserted: 350863\n",
      "[yellow 2016-12] 2016-12-19 00:00:00..2016-12-20 00:00:00 -> inserted: 346870\n",
      "[yellow 2016-12] 2016-12-20 00:00:00..2016-12-21 00:00:00 -> inserted: 356545\n",
      "[yellow 2016-12] 2016-12-21 00:00:00..2016-12-22 00:00:00 -> inserted: 350221\n",
      "[yellow 2016-12] 2016-12-22 00:00:00..2016-12-23 00:00:00 -> inserted: 339864\n",
      "[yellow 2016-12] 2016-12-23 00:00:00..2016-12-24 00:00:00 -> inserted: 315551\n",
      "[yellow 2016-12] 2016-12-24 00:00:00..2016-12-25 00:00:00 -> inserted: 254156\n",
      "[yellow 2016-12] 2016-12-25 00:00:00..2016-12-26 00:00:00 -> inserted: 167841\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o38524.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2016-12] 2016-12-26 00:00:00..2016-12-27 00:00:00 -> inserted: 205078\n",
      "[yellow 2016-12] 2016-12-27 00:00:00..2016-12-28 00:00:00 -> inserted: 248479\n",
      "[yellow 2016-12] 2016-12-28 00:00:00..2016-12-29 00:00:00 -> inserted: 276044\n",
      "[yellow 2016-12] 2016-12-29 00:00:00..2016-12-30 00:00:00 -> inserted: 290231\n",
      "[yellow 2016-12] 2016-12-30 00:00:00..2016-12-31 00:00:00 -> inserted: 303671\n",
      "[yellow 2016-12] 2016-12-31 00:00:00..2017-01-01 00:00:00 -> inserted: 284035\n",
      "\n",
      "=== RESUMEN YELLOW 2016-12 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2016_12\n",
      "Esperadas (parquet): 10446697\n",
      "Insertadas por loop (sin NULL): 10446697\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10446697  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-01.parquet\n",
      "[yellow 2017-01] 2017-01-01 00:00:00..2017-01-02 00:00:00 -> inserted: 281263\n",
      "[yellow 2017-01] 2017-01-02 00:00:00..2017-01-03 00:00:00 -> inserted: 224893\n",
      "[yellow 2017-01] 2017-01-03 00:00:00..2017-01-04 00:00:00 -> inserted: 278099\n",
      "[yellow 2017-01] 2017-01-04 00:00:00..2017-01-05 00:00:00 -> inserted: 289301\n",
      "[yellow 2017-01] 2017-01-05 00:00:00..2017-01-06 00:00:00 -> inserted: 324421\n",
      "[yellow 2017-01] 2017-01-06 00:00:00..2017-01-07 00:00:00 -> inserted: 340685\n",
      "[yellow 2017-01] 2017-01-07 00:00:00..2017-01-08 00:00:00 -> inserted: 305981\n",
      "[yellow 2017-01] 2017-01-08 00:00:00..2017-01-09 00:00:00 -> inserted: 290932\n",
      "[yellow 2017-01] 2017-01-09 00:00:00..2017-01-10 00:00:00 -> inserted: 301996\n",
      "[yellow 2017-01] 2017-01-10 00:00:00..2017-01-11 00:00:00 -> inserted: 305921\n",
      "[yellow 2017-01] 2017-01-11 00:00:00..2017-01-12 00:00:00 -> inserted: 318251\n",
      "[yellow 2017-01] 2017-01-12 00:00:00..2017-01-13 00:00:00 -> inserted: 326816\n",
      "[yellow 2017-01] 2017-01-13 00:00:00..2017-01-14 00:00:00 -> inserted: 344915\n",
      "[yellow 2017-01] 2017-01-14 00:00:00..2017-01-15 00:00:00 -> inserted: 342214\n",
      "[yellow 2017-01] 2017-01-15 00:00:00..2017-01-16 00:00:00 -> inserted: 307477\n",
      "[yellow 2017-01] 2017-01-16 00:00:00..2017-01-17 00:00:00 -> inserted: 260236\n",
      "[yellow 2017-01] 2017-01-17 00:00:00..2017-01-18 00:00:00 -> inserted: 324254\n",
      "[yellow 2017-01] 2017-01-18 00:00:00..2017-01-19 00:00:00 -> inserted: 324382\n",
      "[yellow 2017-01] 2017-01-19 00:00:00..2017-01-20 00:00:00 -> inserted: 332456\n",
      "[yellow 2017-01] 2017-01-20 00:00:00..2017-01-21 00:00:00 -> inserted: 341557\n",
      "[yellow 2017-01] 2017-01-21 00:00:00..2017-01-22 00:00:00 -> inserted: 329093\n",
      "[yellow 2017-01] 2017-01-22 00:00:00..2017-01-23 00:00:00 -> inserted: 292084\n",
      "[yellow 2017-01] 2017-01-23 00:00:00..2017-01-24 00:00:00 -> inserted: 293838\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o39292.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-01] 2017-01-24 00:00:00..2017-01-25 00:00:00 -> inserted: 320990\n",
      "[yellow 2017-01] 2017-01-25 00:00:00..2017-01-26 00:00:00 -> inserted: 325264\n",
      "[yellow 2017-01] 2017-01-26 00:00:00..2017-01-27 00:00:00 -> inserted: 342833\n",
      "[yellow 2017-01] 2017-01-27 00:00:00..2017-01-28 00:00:00 -> inserted: 363952\n",
      "[yellow 2017-01] 2017-01-28 00:00:00..2017-01-29 00:00:00 -> inserted: 368410\n",
      "[yellow 2017-01] 2017-01-29 00:00:00..2017-01-30 00:00:00 -> inserted: 305756\n",
      "[yellow 2017-01] 2017-01-30 00:00:00..2017-01-31 00:00:00 -> inserted: 289127\n",
      "[yellow 2017-01] 2017-01-31 00:00:00..2017-02-01 00:00:00 -> inserted: 313423\n",
      "\n",
      "=== RESUMEN YELLOW 2017-01 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2017_01\n",
      "Esperadas (parquet): 9710820\n",
      "Insertadas por loop (sin NULL): 9710820\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 9710820  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-02.parquet\n",
      "[WARN] ensure table RAW.TRIPS_YELLOW_2017_02: An error occurred while calling o39538.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-02] 2017-02-01 00:00:00..2017-02-02 00:00:00 -> inserted: 329727\n",
      "[yellow 2017-02] 2017-02-02 00:00:00..2017-02-03 00:00:00 -> inserted: 353202\n",
      "[yellow 2017-02] 2017-02-03 00:00:00..2017-02-04 00:00:00 -> inserted: 374750\n",
      "[yellow 2017-02] 2017-02-04 00:00:00..2017-02-05 00:00:00 -> inserted: 366033\n",
      "[yellow 2017-02] 2017-02-05 00:00:00..2017-02-06 00:00:00 -> inserted: 306876\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o39693.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-02] 2017-02-06 00:00:00..2017-02-07 00:00:00 -> inserted: 290260\n",
      "[yellow 2017-02] 2017-02-07 00:00:00..2017-02-08 00:00:00 -> inserted: 326241\n",
      "[yellow 2017-02] 2017-02-08 00:00:00..2017-02-09 00:00:00 -> inserted: 331937\n",
      "[yellow 2017-02] 2017-02-09 00:00:00..2017-02-10 00:00:00 -> inserted: 203196\n",
      "[yellow 2017-02] 2017-02-10 00:00:00..2017-02-11 00:00:00 -> inserted: 352440\n",
      "[yellow 2017-02] 2017-02-11 00:00:00..2017-02-12 00:00:00 -> inserted: 370910\n",
      "[yellow 2017-02] 2017-02-12 00:00:00..2017-02-13 00:00:00 -> inserted: 326187\n",
      "[yellow 2017-02] 2017-02-13 00:00:00..2017-02-14 00:00:00 -> inserted: 320163\n",
      "[yellow 2017-02] 2017-02-14 00:00:00..2017-02-15 00:00:00 -> inserted: 343985\n",
      "[yellow 2017-02] 2017-02-15 00:00:00..2017-02-16 00:00:00 -> inserted: 347254\n",
      "[yellow 2017-02] 2017-02-16 00:00:00..2017-02-17 00:00:00 -> inserted: 368343\n",
      "[yellow 2017-02] 2017-02-17 00:00:00..2017-02-18 00:00:00 -> inserted: 355340\n",
      "[yellow 2017-02] 2017-02-18 00:00:00..2017-02-19 00:00:00 -> inserted: 326391\n",
      "[yellow 2017-02] 2017-02-19 00:00:00..2017-02-20 00:00:00 -> inserted: 299316\n",
      "[yellow 2017-02] 2017-02-20 00:00:00..2017-02-21 00:00:00 -> inserted: 262119\n",
      "[yellow 2017-02] 2017-02-21 00:00:00..2017-02-22 00:00:00 -> inserted: 295500\n",
      "[yellow 2017-02] 2017-02-22 00:00:00..2017-02-23 00:00:00 -> inserted: 314914\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40102.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-02] 2017-02-23 00:00:00..2017-02-24 00:00:00 -> inserted: 335093\n",
      "[yellow 2017-02] 2017-02-24 00:00:00..2017-02-25 00:00:00 -> inserted: 350695\n",
      "[yellow 2017-02] 2017-02-25 00:00:00..2017-02-26 00:00:00 -> inserted: 368410\n",
      "[yellow 2017-02] 2017-02-26 00:00:00..2017-02-27 00:00:00 -> inserted: 320351\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40212.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-02] 2017-02-27 00:00:00..2017-02-28 00:00:00 -> inserted: 305744\n",
      "[yellow 2017-02] 2017-02-28 00:00:00..2017-03-01 00:00:00 -> inserted: 324398\n",
      "\n",
      "=== RESUMEN YELLOW 2017-02 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2017_02\n",
      "Esperadas (parquet): 9169775\n",
      "Insertadas por loop (sin NULL): 9169775\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 9169775  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-03.parquet\n",
      "[yellow 2017-03] 2017-03-01 00:00:00..2017-03-02 00:00:00 -> inserted: 342114\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40382.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-03] 2017-03-02 00:00:00..2017-03-03 00:00:00 -> inserted: 372890\n",
      "[yellow 2017-03] 2017-03-03 00:00:00..2017-03-04 00:00:00 -> inserted: 395438\n",
      "[yellow 2017-03] 2017-03-04 00:00:00..2017-03-05 00:00:00 -> inserted: 404095\n",
      "[yellow 2017-03] 2017-03-05 00:00:00..2017-03-06 00:00:00 -> inserted: 326953\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40491.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-03] 2017-03-06 00:00:00..2017-03-07 00:00:00 -> inserted: 309437\n",
      "[yellow 2017-03] 2017-03-07 00:00:00..2017-03-08 00:00:00 -> inserted: 332351\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40555.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-03] 2017-03-08 00:00:00..2017-03-09 00:00:00 -> inserted: 342606\n",
      "[yellow 2017-03] 2017-03-09 00:00:00..2017-03-10 00:00:00 -> inserted: 362991\n",
      "[yellow 2017-03] 2017-03-10 00:00:00..2017-03-11 00:00:00 -> inserted: 380879\n",
      "[yellow 2017-03] 2017-03-11 00:00:00..2017-03-12 00:00:00 -> inserted: 401203\n",
      "[yellow 2017-03] 2017-03-12 00:00:00..2017-03-13 00:00:00 -> inserted: 335497\n",
      "[yellow 2017-03] 2017-03-13 00:00:00..2017-03-14 00:00:00 -> inserted: 336446\n",
      "[yellow 2017-03] 2017-03-14 00:00:00..2017-03-15 00:00:00 -> inserted: 100371\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40733.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-03] 2017-03-15 00:00:00..2017-03-16 00:00:00 -> inserted: 292175\n",
      "[yellow 2017-03] 2017-03-16 00:00:00..2017-03-17 00:00:00 -> inserted: 316944\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40796.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-03] 2017-03-17 00:00:00..2017-03-18 00:00:00 -> inserted: 319364\n",
      "[yellow 2017-03] 2017-03-18 00:00:00..2017-03-19 00:00:00 -> inserted: 365698\n",
      "[yellow 2017-03] 2017-03-19 00:00:00..2017-03-20 00:00:00 -> inserted: 301011\n",
      "[yellow 2017-03] 2017-03-20 00:00:00..2017-03-21 00:00:00 -> inserted: 285014\n",
      "[yellow 2017-03] 2017-03-21 00:00:00..2017-03-22 00:00:00 -> inserted: 305218\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o40928.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-03] 2017-03-22 00:00:00..2017-03-23 00:00:00 -> inserted: 347405\n",
      "[yellow 2017-03] 2017-03-23 00:00:00..2017-03-24 00:00:00 -> inserted: 345935\n",
      "[yellow 2017-03] 2017-03-24 00:00:00..2017-03-25 00:00:00 -> inserted: 341160\n",
      "[yellow 2017-03] 2017-03-25 00:00:00..2017-03-26 00:00:00 -> inserted: 346831\n",
      "[yellow 2017-03] 2017-03-26 00:00:00..2017-03-27 00:00:00 -> inserted: 303860\n",
      "[yellow 2017-03] 2017-03-27 00:00:00..2017-03-28 00:00:00 -> inserted: 285980\n",
      "[yellow 2017-03] 2017-03-28 00:00:00..2017-03-29 00:00:00 -> inserted: 333163\n",
      "[yellow 2017-03] 2017-03-29 00:00:00..2017-03-30 00:00:00 -> inserted: 331685\n",
      "[yellow 2017-03] 2017-03-30 00:00:00..2017-03-31 00:00:00 -> inserted: 352150\n",
      "[yellow 2017-03] 2017-03-31 00:00:00..2017-04-01 00:00:00 -> inserted: 378577\n",
      "\n",
      "=== RESUMEN YELLOW 2017-03 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2017_03\n",
      "Esperadas (parquet): 10295441\n",
      "Insertadas por loop (sin NULL): 10295441\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10295441  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-04.parquet\n",
      "[yellow 2017-04] 2017-04-01 00:00:00..2017-04-02 00:00:00 -> inserted: 355839\n",
      "[yellow 2017-04] 2017-04-02 00:00:00..2017-04-03 00:00:00 -> inserted: 312919\n",
      "[yellow 2017-04] 2017-04-03 00:00:00..2017-04-04 00:00:00 -> inserted: 304117\n",
      "[yellow 2017-04] 2017-04-04 00:00:00..2017-04-05 00:00:00 -> inserted: 336222\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o41352.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-04] 2017-04-05 00:00:00..2017-04-06 00:00:00 -> inserted: 350517\n",
      "[yellow 2017-04] 2017-04-06 00:00:00..2017-04-07 00:00:00 -> inserted: 363514\n",
      "[yellow 2017-04] 2017-04-07 00:00:00..2017-04-08 00:00:00 -> inserted: 383195\n",
      "[yellow 2017-04] 2017-04-08 00:00:00..2017-04-09 00:00:00 -> inserted: 364527\n",
      "[yellow 2017-04] 2017-04-09 00:00:00..2017-04-10 00:00:00 -> inserted: 316977\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o41484.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-04] 2017-04-10 00:00:00..2017-04-11 00:00:00 -> inserted: 286715\n",
      "[yellow 2017-04] 2017-04-11 00:00:00..2017-04-12 00:00:00 -> inserted: 312053\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o41548.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-04] 2017-04-12 00:00:00..2017-04-13 00:00:00 -> inserted: 325556\n",
      "[yellow 2017-04] 2017-04-13 00:00:00..2017-04-14 00:00:00 -> inserted: 341315\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o41611.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-04] 2017-04-14 00:00:00..2017-04-15 00:00:00 -> inserted: 333233\n",
      "[yellow 2017-04] 2017-04-15 00:00:00..2017-04-16 00:00:00 -> inserted: 312855\n",
      "[yellow 2017-04] 2017-04-16 00:00:00..2017-04-17 00:00:00 -> inserted: 281858\n",
      "[yellow 2017-04] 2017-04-17 00:00:00..2017-04-18 00:00:00 -> inserted: 282431\n",
      "[yellow 2017-04] 2017-04-18 00:00:00..2017-04-19 00:00:00 -> inserted: 326856\n",
      "[yellow 2017-04] 2017-04-19 00:00:00..2017-04-20 00:00:00 -> inserted: 351845\n",
      "[yellow 2017-04] 2017-04-20 00:00:00..2017-04-21 00:00:00 -> inserted: 361371\n",
      "[yellow 2017-04] 2017-04-21 00:00:00..2017-04-22 00:00:00 -> inserted: 380134\n",
      "[yellow 2017-04] 2017-04-22 00:00:00..2017-04-23 00:00:00 -> inserted: 352974\n",
      "[yellow 2017-04] 2017-04-23 00:00:00..2017-04-24 00:00:00 -> inserted: 321247\n",
      "[yellow 2017-04] 2017-04-24 00:00:00..2017-04-25 00:00:00 -> inserted: 310502\n",
      "[yellow 2017-04] 2017-04-25 00:00:00..2017-04-26 00:00:00 -> inserted: 344526\n",
      "[yellow 2017-04] 2017-04-26 00:00:00..2017-04-27 00:00:00 -> inserted: 344703\n",
      "[yellow 2017-04] 2017-04-27 00:00:00..2017-04-28 00:00:00 -> inserted: 350200\n",
      "[yellow 2017-04] 2017-04-28 00:00:00..2017-04-29 00:00:00 -> inserted: 359350\n",
      "[yellow 2017-04] 2017-04-29 00:00:00..2017-04-30 00:00:00 -> inserted: 363831\n",
      "[yellow 2017-04] 2017-04-30 00:00:00..2017-05-01 00:00:00 -> inserted: 315753\n",
      "\n",
      "=== RESUMEN YELLOW 2017-04 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2017_04\n",
      "Esperadas (parquet): 10047135\n",
      "Insertadas por loop (sin NULL): 10047135\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10047135  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-05.parquet\n",
      "[yellow 2017-05] 2017-05-01 00:00:00..2017-05-02 00:00:00 -> inserted: 303360\n",
      "[yellow 2017-05] 2017-05-02 00:00:00..2017-05-03 00:00:00 -> inserted: 332566\n",
      "[yellow 2017-05] 2017-05-03 00:00:00..2017-05-04 00:00:00 -> inserted: 346022\n",
      "[yellow 2017-05] 2017-05-04 00:00:00..2017-05-05 00:00:00 -> inserted: 355577\n",
      "[yellow 2017-05] 2017-05-05 00:00:00..2017-05-06 00:00:00 -> inserted: 362782\n",
      "[yellow 2017-05] 2017-05-06 00:00:00..2017-05-07 00:00:00 -> inserted: 370499\n",
      "[yellow 2017-05] 2017-05-07 00:00:00..2017-05-08 00:00:00 -> inserted: 318027\n",
      "[yellow 2017-05] 2017-05-08 00:00:00..2017-05-09 00:00:00 -> inserted: 306979\n",
      "[yellow 2017-05] 2017-05-09 00:00:00..2017-05-10 00:00:00 -> inserted: 330479\n",
      "[yellow 2017-05] 2017-05-10 00:00:00..2017-05-11 00:00:00 -> inserted: 340369\n",
      "[yellow 2017-05] 2017-05-11 00:00:00..2017-05-12 00:00:00 -> inserted: 348246\n",
      "[yellow 2017-05] 2017-05-12 00:00:00..2017-05-13 00:00:00 -> inserted: 354092\n",
      "[yellow 2017-05] 2017-05-13 00:00:00..2017-05-14 00:00:00 -> inserted: 371150\n",
      "[yellow 2017-05] 2017-05-14 00:00:00..2017-05-15 00:00:00 -> inserted: 297073\n",
      "[yellow 2017-05] 2017-05-15 00:00:00..2017-05-16 00:00:00 -> inserted: 312444\n",
      "[yellow 2017-05] 2017-05-16 00:00:00..2017-05-17 00:00:00 -> inserted: 337218\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o42472.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-05] 2017-05-17 00:00:00..2017-05-18 00:00:00 -> inserted: 352076\n",
      "[yellow 2017-05] 2017-05-18 00:00:00..2017-05-19 00:00:00 -> inserted: 349188\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o42535.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-05] 2017-05-19 00:00:00..2017-05-20 00:00:00 -> inserted: 364286\n",
      "[yellow 2017-05] 2017-05-20 00:00:00..2017-05-21 00:00:00 -> inserted: 367665\n",
      "[yellow 2017-05] 2017-05-21 00:00:00..2017-05-22 00:00:00 -> inserted: 319407\n",
      "[yellow 2017-05] 2017-05-22 00:00:00..2017-05-23 00:00:00 -> inserted: 307309\n",
      "[yellow 2017-05] 2017-05-23 00:00:00..2017-05-24 00:00:00 -> inserted: 323637\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o42668.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-05] 2017-05-24 00:00:00..2017-05-25 00:00:00 -> inserted: 336578\n",
      "[yellow 2017-05] 2017-05-25 00:00:00..2017-05-26 00:00:00 -> inserted: 342445\n",
      "[yellow 2017-05] 2017-05-26 00:00:00..2017-05-27 00:00:00 -> inserted: 306057\n",
      "[yellow 2017-05] 2017-05-27 00:00:00..2017-05-28 00:00:00 -> inserted: 267405\n",
      "[yellow 2017-05] 2017-05-28 00:00:00..2017-05-29 00:00:00 -> inserted: 241410\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o42800.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-05] 2017-05-29 00:00:00..2017-05-30 00:00:00 -> inserted: 213354\n",
      "[yellow 2017-05] 2017-05-30 00:00:00..2017-05-31 00:00:00 -> inserted: 296638\n",
      "[yellow 2017-05] 2017-05-31 00:00:00..2017-06-01 00:00:00 -> inserted: 327789\n",
      "\n",
      "=== RESUMEN YELLOW 2017-05 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2017_05\n",
      "Esperadas (parquet): 10102127\n",
      "Insertadas por loop (sin NULL): 10102127\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 10102127  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-06.parquet\n",
      "[yellow 2017-06] 2017-06-01 00:00:00..2017-06-02 00:00:00 -> inserted: 344507\n",
      "[yellow 2017-06] 2017-06-02 00:00:00..2017-06-03 00:00:00 -> inserted: 347404\n",
      "[yellow 2017-06] 2017-06-03 00:00:00..2017-06-04 00:00:00 -> inserted: 341807\n",
      "[yellow 2017-06] 2017-06-04 00:00:00..2017-06-05 00:00:00 -> inserted: 294236\n",
      "[yellow 2017-06] 2017-06-05 00:00:00..2017-06-06 00:00:00 -> inserted: 304042\n",
      "[yellow 2017-06] 2017-06-06 00:00:00..2017-06-07 00:00:00 -> inserted: 341499\n",
      "[yellow 2017-06] 2017-06-07 00:00:00..2017-06-08 00:00:00 -> inserted: 339808\n",
      "[yellow 2017-06] 2017-06-08 00:00:00..2017-06-09 00:00:00 -> inserted: 353452\n",
      "[yellow 2017-06] 2017-06-09 00:00:00..2017-06-10 00:00:00 -> inserted: 342240\n",
      "[yellow 2017-06] 2017-06-10 00:00:00..2017-06-11 00:00:00 -> inserted: 337959\n",
      "[yellow 2017-06] 2017-06-11 00:00:00..2017-06-12 00:00:00 -> inserted: 283088\n",
      "[yellow 2017-06] 2017-06-12 00:00:00..2017-06-13 00:00:00 -> inserted: 311495\n",
      "[yellow 2017-06] 2017-06-13 00:00:00..2017-06-14 00:00:00 -> inserted: 333931\n",
      "[yellow 2017-06] 2017-06-14 00:00:00..2017-06-15 00:00:00 -> inserted: 349305\n",
      "[yellow 2017-06] 2017-06-15 00:00:00..2017-06-16 00:00:00 -> inserted: 347838\n",
      "[yellow 2017-06] 2017-06-16 00:00:00..2017-06-17 00:00:00 -> inserted: 341823\n",
      "[yellow 2017-06] 2017-06-17 00:00:00..2017-06-18 00:00:00 -> inserted: 318478\n",
      "[yellow 2017-06] 2017-06-18 00:00:00..2017-06-19 00:00:00 -> inserted: 277743\n",
      "[yellow 2017-06] 2017-06-19 00:00:00..2017-06-20 00:00:00 -> inserted: 306068\n",
      "[yellow 2017-06] 2017-06-20 00:00:00..2017-06-21 00:00:00 -> inserted: 318727\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o43430.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:306)\n",
      "\tat net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:167)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executePreparedQueryInterruptibly$1(SnowflakeJDBCWrapper.scala:219)\n",
      "\tat net.snowflake.spark.snowflake.JDBCWrapper.$anonfun$executeInterruptibly$2(SnowflakeJDBCWrapper.scala:266)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-06] 2017-06-21 00:00:00..2017-06-22 00:00:00 -> inserted: 331000\n",
      "[yellow 2017-06] 2017-06-22 00:00:00..2017-06-23 00:00:00 -> inserted: 338890\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o43493.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-06] 2017-06-23 00:00:00..2017-06-24 00:00:00 -> inserted: 341160\n",
      "[yellow 2017-06] 2017-06-24 00:00:00..2017-06-25 00:00:00 -> inserted: 317617\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o43557.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-06] 2017-06-25 00:00:00..2017-06-26 00:00:00 -> inserted: 248929\n",
      "[yellow 2017-06] 2017-06-26 00:00:00..2017-06-27 00:00:00 -> inserted: 290740\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o43621.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-06] 2017-06-27 00:00:00..2017-06-28 00:00:00 -> inserted: 321083\n",
      "[yellow 2017-06] 2017-06-28 00:00:00..2017-06-29 00:00:00 -> inserted: 316000\n",
      "[yellow 2017-06] 2017-06-29 00:00:00..2017-06-30 00:00:00 -> inserted: 313277\n",
      "[yellow 2017-06] 2017-06-30 00:00:00..2017-07-01 00:00:00 -> inserted: 302847\n",
      "\n",
      "=== RESUMEN YELLOW 2017-06 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2017_06\n",
      "Esperadas (parquet): 9656993\n",
      "Insertadas por loop (sin NULL): 9656993\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 9656993  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-07.parquet\n",
      "[yellow 2017-07] 2017-07-01 00:00:00..2017-07-02 00:00:00 -> inserted: 245530\n",
      "[yellow 2017-07] 2017-07-02 00:00:00..2017-07-03 00:00:00 -> inserted: 204086\n",
      "[yellow 2017-07] 2017-07-03 00:00:00..2017-07-04 00:00:00 -> inserted: 193217\n",
      "[yellow 2017-07] 2017-07-04 00:00:00..2017-07-05 00:00:00 -> inserted: 184967\n",
      "[yellow 2017-07] 2017-07-05 00:00:00..2017-07-06 00:00:00 -> inserted: 250623\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o43930.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-07] 2017-07-06 00:00:00..2017-07-07 00:00:00 -> inserted: 276497\n",
      "[yellow 2017-07] 2017-07-07 00:00:00..2017-07-08 00:00:00 -> inserted: 290404\n",
      "[yellow 2017-07] 2017-07-08 00:00:00..2017-07-09 00:00:00 -> inserted: 264365\n",
      "[yellow 2017-07] 2017-07-09 00:00:00..2017-07-10 00:00:00 -> inserted: 243683\n",
      "[yellow 2017-07] 2017-07-10 00:00:00..2017-07-11 00:00:00 -> inserted: 270799\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o44062.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-07] 2017-07-11 00:00:00..2017-07-12 00:00:00 -> inserted: 302257\n",
      "[yellow 2017-07] 2017-07-12 00:00:00..2017-07-13 00:00:00 -> inserted: 320737\n",
      "[yellow 2017-07] 2017-07-13 00:00:00..2017-07-14 00:00:00 -> inserted: 322637\n",
      "[yellow 2017-07] 2017-07-14 00:00:00..2017-07-15 00:00:00 -> inserted: 307834\n",
      "[yellow 2017-07] 2017-07-15 00:00:00..2017-07-16 00:00:00 -> inserted: 277479\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o44194.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-07] 2017-07-16 00:00:00..2017-07-17 00:00:00 -> inserted: 260505\n",
      "[yellow 2017-07] 2017-07-17 00:00:00..2017-07-18 00:00:00 -> inserted: 281214\n",
      "[yellow 2017-07] 2017-07-18 00:00:00..2017-07-19 00:00:00 -> inserted: 307823\n",
      "[yellow 2017-07] 2017-07-19 00:00:00..2017-07-20 00:00:00 -> inserted: 324255\n",
      "[yellow 2017-07] 2017-07-20 00:00:00..2017-07-21 00:00:00 -> inserted: 324259\n",
      "[yellow 2017-07] 2017-07-21 00:00:00..2017-07-22 00:00:00 -> inserted: 311814\n",
      "[yellow 2017-07] 2017-07-22 00:00:00..2017-07-23 00:00:00 -> inserted: 291153\n",
      "[yellow 2017-07] 2017-07-23 00:00:00..2017-07-24 00:00:00 -> inserted: 244083\n",
      "[yellow 2017-07] 2017-07-24 00:00:00..2017-07-25 00:00:00 -> inserted: 274617\n",
      "[yellow 2017-07] 2017-07-25 00:00:00..2017-07-26 00:00:00 -> inserted: 291904\n",
      "[yellow 2017-07] 2017-07-26 00:00:00..2017-07-27 00:00:00 -> inserted: 305520\n",
      "[yellow 2017-07] 2017-07-27 00:00:00..2017-07-28 00:00:00 -> inserted: 315836\n",
      "[yellow 2017-07] 2017-07-28 00:00:00..2017-07-29 00:00:00 -> inserted: 305718\n",
      "[yellow 2017-07] 2017-07-29 00:00:00..2017-07-30 00:00:00 -> inserted: 274531\n",
      "[yellow 2017-07] 2017-07-30 00:00:00..2017-07-31 00:00:00 -> inserted: 254956\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o44557.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-07] 2017-07-31 00:00:00..2017-08-01 00:00:00 -> inserted: 265183\n",
      "\n",
      "=== RESUMEN YELLOW 2017-07 ===\n",
      "Tabla RAW destino: RAW.TRIPS_YELLOW_2017_07\n",
      "Esperadas (parquet): 8588486\n",
      "Insertadas por loop (sin NULL): 8588486\n",
      "Insertadas NULL: 0\n",
      "Filas en RAW: 8588486  --> OK\n",
      "\n",
      "Descargando: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-08.parquet\n",
      "[yellow 2017-08] 2017-08-01 00:00:00..2017-08-02 00:00:00 -> inserted: 288945\n",
      "[yellow 2017-08] 2017-08-02 00:00:00..2017-08-03 00:00:00 -> inserted: 306301\n",
      "[yellow 2017-08] 2017-08-03 00:00:00..2017-08-04 00:00:00 -> inserted: 314611\n",
      "[yellow 2017-08] 2017-08-04 00:00:00..2017-08-05 00:00:00 -> inserted: 297206\n",
      "[yellow 2017-08] 2017-08-05 00:00:00..2017-08-06 00:00:00 -> inserted: 263708\n",
      "[yellow 2017-08] 2017-08-06 00:00:00..2017-08-07 00:00:00 -> inserted: 239352\n",
      "[yellow 2017-08] 2017-08-07 00:00:00..2017-08-08 00:00:00 -> inserted: 269842\n",
      "[yellow 2017-08] 2017-08-08 00:00:00..2017-08-09 00:00:00 -> inserted: 279735\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o44865.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLException: JDBC driver internal error: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null.\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.executeInternal(SnowflakeStatementV1.java:382)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeStatementV1.execute(SnowflakeStatementV1.java:425)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.executeImmediate(SnowflakeConnectionV1.java:182)\n",
      "\tat net.snowflake.client.jdbc.SnowflakeConnectionV1.commit(SnowflakeConnectionV1.java:394)\n",
      "\tat net.snowflake.spark.snowflake.ServerConnection.commit(ServerConnection.scala:338)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:471)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[yellow 2017-08] 2017-08-09 00:00:00..2017-08-10 00:00:00 -> inserted: 293058\n",
      "[yellow 2017-08] 2017-08-10 00:00:00..2017-08-11 00:00:00 -> inserted: 306138\n",
      "[WARN] write intento 1/3 falló: An error occurred while calling o44928.save.\n",
      ": net.snowflake.client.jdbc.SnowflakeSQLLoggedException: !-1!\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:246)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryStatus(SFSession.java:305)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getStatus(SFAsyncResultSet.java:107)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getRealResults(SFAsyncResultSet.java:183)\n",
      "\tat net.snowflake.client.jdbc.SFAsyncResultSet.getMetaData(SFAsyncResultSet.java:298)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.executeCopyIntoTable(StageWriter.scala:575)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTableWithStagingTable(StageWriter.scala:452)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToTable(StageWriter.scala:288)\n",
      "\tat net.snowflake.spark.snowflake.io.StageWriter$.writeToStage(StageWriter.scala:233)\n",
      "\tat net.snowflake.spark.snowflake.io.package$.writeRDD(package.scala:50)\n",
      "\tat net.snowflake.spark.snowflake.SnowflakeWriter.save(SnowflakeWriter.scala:110)\n",
      "\tat net.snowflake.spark.snowflake.DefaultSource.createRelation(DefaultSource.scala:113)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor126.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"net.snowflake.client.jdbc.internal.apache.http.client.methods.CloseableHttpResponse.getStatusLine()\" because \"response\" is null\n",
      "\tat net.snowflake.client.jdbc.RestRequest.sendIBHttpErrorEvent(RestRequest.java:1482)\n",
      "\tat net.snowflake.client.jdbc.RestRequest.executeWithRetries(RestRequest.java:1053)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequestInternal(HttpUtil.java:1254)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeRequest(HttpUtil.java:1157)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:881)\n",
      "\tat net.snowflake.client.core.HttpUtil.executeGeneralRequest(HttpUtil.java:811)\n",
      "\tat net.snowflake.client.core.SFSession.getQueryMetadata(SFSession.java:232)\n",
      "\t... 51 more\n",
      "\n",
      "[yellow 2017-08] 2017-08-11 00:00:00..2017-08-12 00:00:00 -> inserted: 287102\n",
      "[yellow 2017-08] 2017-08-12 00:00:00..2017-08-13 00:00:00 -> inserted: 254633\n",
      "[yellow 2017-08] 2017-08-13 00:00:00..2017-08-14 00:00:00 -> inserted: 227861\n",
      "[yellow 2017-08] 2017-08-14 00:00:00..2017-08-15 00:00:00 -> inserted: 241900\n",
      "[yellow 2017-08] 2017-08-15 00:00:00..2017-08-16 00:00:00 -> inserted: 274507\n",
      "[yellow 2017-08] 2017-08-16 00:00:00..2017-08-17 00:00:00 -> inserted: 285120\n",
      "[yellow 2017-08] 2017-08-17 00:00:00..2017-08-18 00:00:00 -> inserted: 291076\n",
      "[yellow 2017-08] 2017-08-18 00:00:00..2017-08-19 00:00:00 -> inserted: 287746\n",
      "[yellow 2017-08] 2017-08-19 00:00:00..2017-08-20 00:00:00 -> inserted: 263458\n",
      "[yellow 2017-08] 2017-08-20 00:00:00..2017-08-21 00:00:00 -> inserted: 240126\n",
      "[yellow 2017-08] 2017-08-21 00:00:00..2017-08-22 00:00:00 -> inserted: 249906\n",
      "[yellow 2017-08] 2017-08-22 00:00:00..2017-08-23 00:00:00 -> inserted: 284356\n",
      "[yellow 2017-08] 2017-08-23 00:00:00..2017-08-24 00:00:00 -> inserted: 285496\n",
      "[yellow 2017-08] 2017-08-24 00:00:00..2017-08-25 00:00:00 -> inserted: 282979\n",
      "[yellow 2017-08] 2017-08-25 00:00:00..2017-08-26 00:00:00 -> inserted: 271449\n",
      "[yellow 2017-08] 2017-08-26 00:00:00..2017-08-27 00:00:00 -> inserted: 249491\n",
      "[yellow 2017-08] 2017-08-27 00:00:00..2017-08-28 00:00:00 -> inserted: 235503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 193\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    188\u001b[0m pre_sql \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDELETE FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_table\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWHERE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m >= TO_TIMESTAMP_NTZ(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  AND \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <  TO_TIMESTAMP_NTZ(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m )\n\u001b[0;32m--> 193\u001b[0m \u001b[43mwrite_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_sql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m inserted_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cnt\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msvc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> inserted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcnt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 68\u001b[0m, in \u001b[0;36mwrite_with_retry\u001b[0;34m(df_day, target_table, pre_sql, tries)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, tries\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m         (\u001b[43mdf_day\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msnowflake\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msfOptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallelism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musestagingtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msupport_share_connection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfalse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreactions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_sql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 68\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:1461\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === Backfill robusto 2015–2025 (yellow+green) RAW.TRIPS_<SVC>_<YYYY>_<MM> ===\n",
    "import calendar\n",
    "import os, pathlib, urllib.request, time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "BASE_URL = os.getenv(\"DATA_BASE_URL\")\n",
    "assert BASE_URL, \"Falta DATA_BASE_URL en .env\"\n",
    "\n",
    "LOCAL_DIR = \"/home/jovyan/work/datasets/trip-data\"\n",
    "pathlib.Path(LOCAL_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parse env ranges\n",
    "def parse_years(s):\n",
    "    if \"-\" in s:\n",
    "        a, b = s.split(\"-\", 1)\n",
    "        return [str(y) for y in range(int(a), int(b) + 1)]\n",
    "    return [x.strip() for x in s.split(\",\") if x.strip()]\n",
    "\n",
    "def parse_csv(s):\n",
    "    return [x.strip() for x in s.split(\",\") if x.strip()]\n",
    "\n",
    "SERVICES = parse_csv(os.getenv(\"SERVICES\") or \"yellow,green\")\n",
    "YEARS    = parse_years(os.getenv(\"YEARS\") or \"2019-2019\")\n",
    "MONTHS   = parse_csv(os.getenv(\"MONTHS\") or \"01,02,03,04,05,06,07,08,09,10,11,12\")\n",
    "\n",
    "def pickup_col(svc: str) -> str:\n",
    "    return \"tpep_pickup_datetime\" if svc == \"yellow\" else \"lpep_pickup_datetime\"\n",
    "\n",
    "def dropoff_col(svc: str) -> str:\n",
    "    return \"tpep_dropoff_datetime\" if svc == \"yellow\" else \"lpep_dropoff_datetime\"\n",
    "\n",
    "def filename(svc: str, y: str, m: str) -> str:\n",
    "    return f\"{svc}_tripdata_{y}-{m}.parquet\"\n",
    "\n",
    "def ensure_local(remote_url: str, local_path: str, tries=3):\n",
    "    if os.path.exists(local_path):\n",
    "        return\n",
    "    last = None\n",
    "    for a in range(1, tries+1):\n",
    "        try:\n",
    "            print(f\"Descargando: {remote_url}\")\n",
    "            urllib.request.urlretrieve(remote_url, local_path)\n",
    "            return\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            print(f\"[WARN] descarga intento {a}/{tries} falló: {e}\")\n",
    "            time.sleep(3)\n",
    "    raise last\n",
    "\n",
    "def write_with_retry(df_day, target_table, pre_sql, tries=3):\n",
    "    \"\"\"DELETE previo + append; reintenta hasta 3 veces.\"\"\"\n",
    "    last = None\n",
    "    for a in range(1, tries+1):\n",
    "        try:\n",
    "            (df_day.write.format(\"snowflake\")\n",
    "             .options(**sfOptions)\n",
    "             .option(\"dbtable\", target_table)\n",
    "             .option(\"parallelism\", \"1\")\n",
    "             .option(\"usestagingtable\", \"off\")\n",
    "             .option(\"support_share_connection\", \"false\")\n",
    "             .option(\"preactions\", pre_sql)\n",
    "             .mode(\"append\")\n",
    "             .save())\n",
    "            return\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            print(f\"[WARN] write intento {a}/{tries} falló: {e}\")\n",
    "            time.sleep(5)\n",
    "    raise last\n",
    "def sf_count_rows(table: str, tries: int = 5, wait_s: int = 5) -> int:\n",
    "    \"\"\"\n",
    "    Cuenta filas con SELECT COUNT(*) ... usando conexión no compartida y reintentos.\n",
    "    Evita el path de metadata que dispara el 'response is null'.\n",
    "    \"\"\"\n",
    "    last = None\n",
    "    for a in range(1, tries + 1):\n",
    "        try:\n",
    "            df = (spark.read.format(\"snowflake\")\n",
    "                  .options(**sfOptions)\n",
    "                  .option(\"support_share_connection\", \"false\")\n",
    "                  .option(\"query\", f\"SELECT COUNT(*) AS C FROM {table}\")\n",
    "                  .load())\n",
    "            return int(df.collect()[0][\"C\"])\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            print(f\"[WARN] count intento {a}/{tries} falló: {e}\")\n",
    "            time.sleep(wait_s)\n",
    "    raise last\n",
    "\n",
    "def sf_try_count_rows(table: str, tries: int = 5, wait_s: int = 5):\n",
    "    \"\"\"\n",
    "    Versión leniente: devuelve (ok, count_or_None). No detiene el backfill si la verificación falla.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = sf_count_rows(table, tries=tries, wait_s=wait_s)\n",
    "        return True, c\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] verificación final omitida por error persistente: {e}\")\n",
    "        return False, None\n",
    "        \n",
    "run_id_global = os.getenv(\"RUN_ID\") or f\"manual_{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}\"\n",
    "\n",
    "coverage = []  # (svc, y, m, expected, final_cnt, inserted_total, nulls_cnt)\n",
    "\n",
    "for svc in SERVICES:\n",
    "    pcol = pickup_col(svc)\n",
    "    dcol = dropoff_col(svc)\n",
    "\n",
    "    for y in YEARS:\n",
    "        for m in MONTHS:\n",
    "            remote = f\"{BASE_URL}/{filename(svc, y, m)}\"\n",
    "            local  = f\"{LOCAL_DIR}/{filename(svc, y, m)}\"\n",
    "            target_table = f\"RAW.TRIPS_{svc.upper()}_{y}_{m}\"\n",
    "\n",
    "            # 0) Descarga (si falta)\n",
    "            try:\n",
    "                ensure_local(remote, local)\n",
    "            except Exception as e:\n",
    "                print(f\"[SKIP] No se pudo obtener {remote}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # 1) Leer y normalizar timestamps\n",
    "            df = spark.read.parquet(local)\n",
    "            if pcol not in df.columns or dcol not in df.columns:\n",
    "                print(f\"[SKIP] {svc} {y}-{m} sin columnas {pcol}/{dcol}\")\n",
    "                continue\n",
    "\n",
    "            df = df.withColumn(pcol, col(pcol).cast(TimestampType())) \\\n",
    "                   .withColumn(dcol, col(dcol).cast(TimestampType()))\n",
    "\n",
    "            expected = df.count()\n",
    "\n",
    "            # 2) Metadatos consistentes\n",
    "            run_id = run_id_global  # mismo run_id para todo el backfill\n",
    "            df_base = (df\n",
    "                .withColumn(\"run_id\",          lit(run_id))\n",
    "                .withColumn(\"service_type\",    lit(svc))\n",
    "                .withColumn(\"source_year\",     lit(y))\n",
    "                .withColumn(\"source_month\",    lit(m))\n",
    "                .withColumn(\"source_path\",     lit(remote))\n",
    "                .withColumn(\"ingested_at_utc\", lit(datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")))\n",
    "            )\n",
    "\n",
    "            # 3) Asegurar que la tabla existe (schema) con operación ligera\n",
    "            try:\n",
    "                (df_base.limit(0).write.format(\"snowflake\")\n",
    "                 .options(**sfOptions)\n",
    "                 .option(\"dbtable\", target_table)\n",
    "                 .option(\"usestagingtable\", \"off\")\n",
    "                 .option(\"support_share_connection\", \"false\")\n",
    "                 .mode(\"append\")\n",
    "                 .save())\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] ensure table {target_table}: {e}\")\n",
    "\n",
    "            # 4) TRUNCATE del mes al inicio (para idempotencia total del mes)\n",
    "            try:\n",
    "                (df_base.limit(0).write.format(\"snowflake\")\n",
    "                 .options(**sfOptions)\n",
    "                 .option(\"dbtable\", target_table)\n",
    "                 .option(\"preactions\", f\"TRUNCATE TABLE {target_table}\")\n",
    "                 .option(\"usestagingtable\", \"off\")\n",
    "                 .option(\"support_share_connection\", \"false\")\n",
    "                 .mode(\"overwrite\")\n",
    "                 .save())\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] truncate {target_table}: {e}\")\n",
    "\n",
    "            # 5) Carga por día con DELETE [lo,hi) antes de cada intento\n",
    "            inserted_total = 0\n",
    "            last_day = calendar.monthrange(int(y), int(m))[1]  # 28/29/30/31 según el mes/año\n",
    "            for d in range(1, last_day + 1):\n",
    "                day_dt  = datetime.strptime(f\"{y}-{m}-{d:02d} 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "                next_dt = day_dt + timedelta(days=1)\n",
    "                lo = day_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                hi = next_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                part = df_base.filter((col(pcol) >= lo) & (col(pcol) < hi)).coalesce(1)\n",
    "                cnt  = part.count()\n",
    "                if cnt == 0:\n",
    "                    continue\n",
    "\n",
    "                pre_sql = (\n",
    "                    f\"DELETE FROM {target_table} \"\n",
    "                    f\"WHERE {pcol} >= TO_TIMESTAMP_NTZ('{lo}') \"\n",
    "                    f\"  AND {pcol} <  TO_TIMESTAMP_NTZ('{hi}')\"\n",
    "                )\n",
    "                write_with_retry(part, target_table, pre_sql, tries=3)\n",
    "                inserted_total += cnt\n",
    "                print(f\"[{svc} {y}-{m}] {lo}..{hi} -> inserted: {cnt}\")\n",
    "\n",
    "            # 6) Bucket NULL: filas sin pickup (idempotente con DELETE IS NULL)\n",
    "            df_nulls = df_base.filter(col(pcol).isNull()).coalesce(1)\n",
    "            cnt_nulls = df_nulls.count()\n",
    "            if cnt_nulls > 0:\n",
    "                pre_sql_null = (\n",
    "                    f\"DELETE FROM {target_table} \"\n",
    "                    f\"WHERE {pcol} IS NULL AND source_year='{y}' AND source_month='{m}'\"\n",
    "                )\n",
    "                write_with_retry(df_nulls, target_table, pre_sql_null, tries=3)\n",
    "                print(f\"[{svc} {y}-{m}] NULL bucket -> inserted: {cnt_nulls}\")\n",
    "\n",
    "           # 7) Verificación final del mes (robusta con reintentos)\n",
    "            ok_count, final_cnt = sf_try_count_rows(target_table, tries=5, wait_s=5)\n",
    "            \n",
    "            if ok_count:\n",
    "                ok = \"OK\" if final_cnt == expected else f\"MISMATCH ({final_cnt} vs {expected})\"\n",
    "            else:\n",
    "                final_cnt = -1\n",
    "                ok = f\"MISMATCH (count_failed vs expected={expected})\"\n",
    "            \n",
    "            coverage.append((svc, y, m, expected, final_cnt, inserted_total, cnt_nulls, ok))\n",
    "            print(f\"\\n=== RESUMEN {svc.upper()} {y}-{m} ===\")\n",
    "            print(f\"Tabla RAW destino: {target_table}\")\n",
    "            print(f\"Esperadas (parquet): {expected}\")\n",
    "            print(f\"Insertadas por loop (sin NULL): {inserted_total}\")\n",
    "            print(f\"Insertadas NULL: {cnt_nulls}\")\n",
    "            print(f\"Filas en RAW: {final_cnt if final_cnt>=0 else 'COUNT_FAILED'}  --> {ok}\\n\")\n",
    "\n",
    "# 8) Resumen global\n",
    "print(\"\\n================= COBERTURA GLOBAL =================\")\n",
    "for row in coverage:\n",
    "    svc, y, m, expc, finalc, ins, nulls, ok = row\n",
    "    print(f\"{svc:6s} {y}-{m}: final={finalc} expected={expc} inserted={ins} nulls={nulls} -> {ok}\")\n",
    "print(\"====================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a88e8-365b-4dd1-bc5d-4d24e2653a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
